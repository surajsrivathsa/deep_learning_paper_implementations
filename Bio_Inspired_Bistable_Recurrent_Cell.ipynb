{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bio-Inspired-Bistable_Recurrent_Cell.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eYowiuRRONxv",
        "mhM-0LZiPf9c",
        "EWIxTROhQp-E"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPhlXVIfZLCcQDcpZw7B8ig",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajsrivathsa/deep_learning_paper_implementations/blob/master/Bio_Inspired_Bistable_Recurrent_Cell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od63TDJ8Nltv",
        "colab_type": "text"
      },
      "source": [
        "# Bio Inspired Recurrent Cell\n",
        "**For Long lasting memory**\n",
        "\n",
        "paper link: https://arxiv.org/pdf/2006.05252\n",
        "\n",
        "paper discussion link: https://www.youtube.com/watch?v=DLq1DUcMh1Q\n",
        "\n",
        "Credits: Yannic Kilcher (https://www.bitchute.com/video/TLuAfQz5SlKF/ )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYowiuRRONxv",
        "colab_type": "text"
      },
      "source": [
        "# **Tasks**\n",
        "\n",
        "1. Code in a BRC, NBRC and GRU cells\n",
        "\n",
        "2. Compare BRC vs NBRC vs GRU for a simple dataset\n",
        "\n",
        "3. Make notes, Plot graphs\n",
        "\n",
        "4. Analyze advantages and disadvantages of BRC/NBRC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzGuyKBWFMoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import copy\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WskkGq0OySh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "430a99d8-a52d-48da-8cb5-5ae5ebce425c"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras import initializers\n",
        "import tensorboard\n",
        "import time\n",
        "from datetime import datetime\n",
        "from keras import backend as K\n",
        "from prepare_data import parse_seq\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOVg3XiiPSR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3dc5932f-874e-4fc7-a300-6d29f14a05dc"
      },
      "source": [
        " print(os.getcwd())\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVpXcfFOPbsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "248c25cd-17c9-4ea3-dbe1-a5b9241bda54"
      },
      "source": [
        "path = '.'\n",
        " \n",
        "files = os.listdir(path)\n",
        "for name in files:\n",
        "    print(name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".config\n",
            "skp.tfrecords\n",
            "prepare_data.py\n",
            "skp_vocab\n",
            "__pycache__\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhM-0LZiPf9c",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtV-1U35PbvY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7f8e4cde-7e1a-4f45-a5b2-02a79a57a67e"
      },
      "source": [
        "\n",
        "# this is just a datasets of \"bytes\" (not understandable)\n",
        "data = tf.data.TFRecordDataset(\"skp.tfrecords\")\n",
        "\n",
        "# this maps a parser function that properly interprets the bytes over the dataset\n",
        "# (with fixed sequence length 200)\n",
        "# if you change the sequence length in preprocessing you also need to change it here\n",
        "data = data.map(lambda x: parse_seq(x, 200))\n",
        "\n",
        "# a map from characters to indices\n",
        "vocab = pickle.load(open(\"skp_vocab\", mode=\"rb\"))\n",
        "vocab_size = len(vocab)\n",
        "# inverse mapping: indices to characters\n",
        "ind_to_ch = {ind: ch for (ch, ind) in vocab.items()}\n",
        "\n",
        "print(vocab)\n",
        "print(vocab_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 1, 'C': 2, 'l': 3, '!': 4, '?': 5, 'q': 6, 'f': 7, 't': 8, 'J': 9, 'n': 10, ':': 11, 'i': 12, 'r': 13, 'R': 14, 's': 15, ' ': 16, 'v': 17, 'I': 18, 'V': 19, '-': 20, 'Z': 21, 'X': 22, 'z': 23, 'e': 24, 'U': 25, 'F': 26, 'N': 27, '[': 28, 'm': 29, 'S': 30, 'd': 31, 'O': 32, '3': 33, 'a': 34, ']': 35, 'W': 36, 'c': 37, 'k': 38, 'Y': 39, 'L': 40, 'P': 41, 'w': 42, 'B': 43, \"'\": 44, 'E': 45, 'x': 46, 'H': 47, 'M': 48, 'u': 49, ',': 50, 'y': 51, 'h': 52, 'Q': 53, '&': 54, 'G': 55, 'b': 56, 'D': 57, '$': 58, 'K': 59, 'T': 60, 'o': 61, '.': 62, 'g': 63, 'j': 64, ';': 65, 'A': 66, 'p': 67, '<S>': 0}\n",
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnWFxQsoPb1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehotencode(ds):\n",
        "  \n",
        "  new_data = tf.one_hot(indices = ds, depth = vocab_size)\n",
        "  return new_data;\n",
        "\n",
        "new_data = data.map(onehotencode)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CPJDSNSPbzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7521028f-d455-4dcc-b24c-3c0920e95957"
      },
      "source": [
        "cnt = 0\n",
        "counter = 0\n",
        "for element in data:\n",
        "  counter = counter + 1\n",
        "  print(element)\n",
        "  if(counter > 5):\n",
        "    break;"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[ 0 26 12 13 15  8 16  2 12  8 12 23 24 10 11  1 43 24  7 61 13 24 16 42\n",
            " 24 16 67 13 61 37 24 24 31 16 34 10 51 16  7 49 13  8 52 24 13 50 16 52\n",
            " 24 34 13 16 29 24 16 15 67 24 34 38 62  1  1 66  3  3 11  1 30 67 24 34\n",
            " 38 50 16 15 67 24 34 38 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10\n",
            " 11  1 39 61 49 16 34 13 24 16 34  3  3 16 13 24 15 61  3 17 24 31 16 13\n",
            " 34  8 52 24 13 16  8 61 16 31 12 24 16  8 52 34 10 16  8 61 16  7 34 29\n",
            " 12 15 52  5  1  1 66  3  3 11  1 14 24 15 61  3 17 24 31 62 16 13 24 15\n",
            " 61  3 17 24 31 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10 11  1 26\n",
            " 12 13 15  8 50 16 51 61], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0  8 16  2 12  8 12 23 24 10 11  1 26 12 13 15  8 50 16 51 61 49 16 38\n",
            " 10 61 42 16  2 34 12 49 15 16 48 34 13 37 12 49 15 16 12 15 16 37 52 12\n",
            " 24  7 16 24 10 24 29 51 16  8 61 16  8 52 24 16 67 24 61 67  3 24 62  1\n",
            "  1 66  3  3 11  1 36 24 16 38 10 61 42 44  8 50 16 42 24 16 38 10 61 42\n",
            " 44  8 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10 11  1 40 24  8 16\n",
            " 49 15 16 38 12  3  3 16 52 12 29 50 16 34 10 31 16 42 24 44  3  3 16 52\n",
            " 34 17 24 16 37 61 13 10 16 34  8 16 61 49 13 16 61 42 10 16 67 13 12 37\n",
            " 24 62  1 18 15 44  8 16 34 16 17 24 13 31 12 37  8  5  1  1 66  3  3 11\n",
            "  1 27 61 16 29 61 13 24], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 13 31 12 37  8  5  1  1 66  3  3 11  1 27 61 16 29 61 13 24 16  8 34\n",
            "  3 38 12 10 63 16 61 10 44  8 65 16  3 24  8 16 12  8 16 56 24 16 31 61\n",
            " 10 24 11 16 34 42 34 51 50 16 34 42 34 51  4  1  1 30 24 37 61 10 31 16\n",
            "  2 12  8 12 23 24 10 11  1 32 10 24 16 42 61 13 31 50 16 63 61 61 31 16\n",
            " 37 12  8 12 23 24 10 15 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10\n",
            " 11  1 36 24 16 34 13 24 16 34 37 37 61 49 10  8 24 31 16 67 61 61 13 16\n",
            " 37 12  8 12 23 24 10 15 50 16  8 52 24 16 67 34  8 13 12 37 12 34 10 15\n",
            " 16 63 61 61 31 62  1 36 52 34  8 16 34 49  8 52 61 13 12  8 51 16 15 49\n",
            " 13  7 24 12  8 15 16 61], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 34 49  8 52 61 13 12  8 51 16 15 49 13  7 24 12  8 15 16 61 10 16 42\n",
            " 61 49  3 31 16 13 24  3 12 24 17 24 16 49 15 11 16 12  7 16  8 52 24 51\n",
            "  1 42 61 49  3 31 16 51 12 24  3 31 16 49 15 16 56 49  8 16  8 52 24 16\n",
            " 15 49 67 24 13  7  3 49 12  8 51 50 16 42 52 12  3 24 16 12  8 16 42 24\n",
            " 13 24  1 42 52 61  3 24 15 61 29 24 50 16 42 24 16 29 12 63 52  8 16 63\n",
            " 49 24 15 15 16  8 52 24 51 16 13 24  3 12 24 17 24 31 16 49 15 16 52 49\n",
            " 29 34 10 24  3 51 65  1 56 49  8 16  8 52 24 51 16  8 52 12 10 38 16 42\n",
            " 24 16 34 13 24 16  8 61 61 16 31 24 34 13 11 16  8 52 24 16  3 24 34 10\n",
            " 10 24 15 15 16  8 52 34], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 34 13 11 16  8 52 24 16  3 24 34 10 10 24 15 15 16  8 52 34  8  1 34\n",
            "  7  7  3 12 37  8 15 16 49 15 50 16  8 52 24 16 61 56 64 24 37  8 16 61\n",
            "  7 16 61 49 13 16 29 12 15 24 13 51 50 16 12 15 16 34 15 16 34 10  1 12\n",
            " 10 17 24 10  8 61 13 51 16  8 61 16 67 34 13  8 12 37 49  3 34 13 12 15\n",
            " 24 16  8 52 24 12 13 16 34 56 49 10 31 34 10 37 24 65 16 61 49 13  1 15\n",
            " 49  7  7 24 13 34 10 37 24 16 12 15 16 34 16 63 34 12 10 16  8 61 16  8\n",
            " 52 24 29 16 40 24  8 16 49 15 16 13 24 17 24 10 63 24 16  8 52 12 15 16\n",
            " 42 12  8 52  1 61 49 13 16 67 12 38 24 15 50 16 24 13 24 16 42 24 16 56\n",
            " 24 37 61 29 24 16 13 34], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 24 15 50 16 24 13 24 16 42 24 16 56 24 37 61 29 24 16 13 34 38 24 15\n",
            " 11 16  7 61 13 16  8 52 24 16 63 61 31 15 16 38 10 61 42 16 18  1 15 67\n",
            " 24 34 38 16  8 52 12 15 16 12 10 16 52 49 10 63 24 13 16  7 61 13 16 56\n",
            " 13 24 34 31 50 16 10 61  8 16 12 10 16  8 52 12 13 15  8 16  7 61 13 16\n",
            " 13 24 17 24 10 63 24 62  1  1 30 24 37 61 10 31 16  2 12  8 12 23 24 10\n",
            " 11  1 36 61 49  3 31 16 51 61 49 16 67 13 61 37 24 24 31 16 24 15 67 24\n",
            " 37 12 34  3  3 51 16 34 63 34 12 10 15  8 16  2 34 12 49 15 16 48 34 13\n",
            " 37 12 49 15  5  1  1 66  3  3 11  1 66 63 34 12 10 15  8 16 52 12 29 16\n",
            "  7 12 13 15  8 11 16 52], shape=(200,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t57QtvIAQDws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eab66ddd-ea71-4416-9a3c-f1f63ccaa3a7"
      },
      "source": [
        "cnt = 0\n",
        "for element in data:\n",
        "  cnt = cnt+1\n",
        "print(cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWIxTROhQp-E",
        "colab_type": "text"
      },
      "source": [
        "# GRU Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80moQlnxQDz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters(n_h, vocab_size):\n",
        "  parameter_dict = {}\n",
        "\n",
        "  parameter_dict[\"W_h\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[n_h, n_h + vocab_size]))\n",
        "  print(\"W_h: \" + str(parameter_dict[\"W_h\"].shape))\n",
        "  parameter_dict[\"b_h\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 2)(shape=[ n_h, 1]))\n",
        "  print(\"b_h: \" + str(parameter_dict[\"b_h\"].shape))\n",
        "\n",
        "\n",
        "  parameter_dict[\"W_u\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 3)(shape=[n_h, n_h + vocab_size]))\n",
        "  print(\"W_u: \" + str(parameter_dict[\"W_u\"].shape))\n",
        "  parameter_dict[\"b_u\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 2)(shape=[ n_h, 1]))\n",
        "  print(\"b_u: \" + str(parameter_dict[\"b_u\"].shape))\n",
        "\n",
        "  parameter_dict[\"W_r\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 4)(shape=[n_h, n_h + vocab_size]))\n",
        "  print(\"W_r: \" + str(parameter_dict[\"W_r\"].shape))\n",
        "  parameter_dict[\"b_r\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 5)(shape=[ n_h, 1]))\n",
        "  print(\"b_r: \" + str(parameter_dict[\"b_r\"].shape))\n",
        "\n",
        "  parameter_dict[\"W_o\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 7)(shape=[n_h, vocab_size]))\n",
        "  print(\"W_o: \" + str(parameter_dict[\"W_o\"].shape))\n",
        "  parameter_dict[\"b_o\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 6)(shape=[ 1, vocab_size]))\n",
        "  print(\"b_o: \" + str(parameter_dict[\"b_o\"].shape))\n",
        "  \n",
        "  return parameter_dict;"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlwEEIUUQD2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ones_tensor = tf.Variable(tf.ones(shape =[512, 128], dtype=tf.dtypes.float32))\n",
        "\n",
        "def gru_forward_compute(x_t, parameter_dict, h_prev):\n",
        "\n",
        "  stacked_input = tf.concat([h_prev, tf.transpose(x_t)], axis = 0)\n",
        "  \n",
        "  update_gate = tf.nn.sigmoid(tf.matmul(parameter_dict[\"W_u\"], stacked_input ) + parameter_dict[\"b_u\"])\n",
        "  #print(update_gate.shape)\n",
        "\n",
        "  reset_gate = tf.nn.sigmoid(tf.matmul(parameter_dict[\"W_r\"], stacked_input ) + parameter_dict[\"b_r\"])\n",
        "  #print(reset_gate.shape)\n",
        "\n",
        "  hadamard_product = tf.multiply(reset_gate, h_prev)\n",
        "  stacked_cell_input = tf.concat([hadamard_product, tf.transpose(x_t)], axis = 0)\n",
        "  h_tilde = tf.nn.tanh(tf.matmul(parameter_dict[\"W_h\"], stacked_cell_input ) + parameter_dict[\"b_h\"])\n",
        "\n",
        "  \n",
        "  h = tf.multiply(update_gate, h_tilde) + tf.multiply(tf.subtract(ones_tensor, update_gate), h_prev)\n",
        "\n",
        "  logits = tf.matmul(tf.transpose(h), parameter_dict[\"W_o\"] ) + parameter_dict[\"b_o\"]\n",
        "  softmax_output = tf.nn.softmax(logits,axis = 0)\n",
        "\n",
        "  return [update_gate, reset_gate, h, logits, softmax_output];"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiNwso5CQ5dm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "b20d0c80-bfb5-4011-9c5e-cae4b214d9e8"
      },
      "source": [
        "parameter_dict = initialize_parameters(n_h=512, vocab_size=vocab_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_h: (512, 580)\n",
            "b_h: (512, 1)\n",
            "W_u: (512, 580)\n",
            "b_u: (512, 1)\n",
            "W_r: (512, 580)\n",
            "b_r: (512, 1)\n",
            "W_o: (512, 68)\n",
            "b_o: (1, 68)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGOrK_XpQ5gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[128, vocab_size]))\n",
        "h_prev = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[512, 128]))\n",
        "update_gate, reset_gate, h, logits, softmax_output = gru_forward_compute(x_t, parameter_dict, h_prev)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Xfiqc0RYZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ca3d568-c4f5-4aba-dd47-5c4766467fdc"
      },
      "source": [
        "tf.shape(softmax_output)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([128,  68], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dKUl1m1RFyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "fdab945d-30bf-4ab8-d942-648fb73b2ea7"
      },
      "source": [
        "#print(update_gate)\n",
        "#print(h)\n",
        "print(tf.reduce_sum(softmax_output[:, 2]))\n",
        "print(softmax_output[:, 2])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[0.00768709 0.00754427 0.00781152 0.00689983 0.00797018 0.00783288\n",
            " 0.00819303 0.00695316 0.00779048 0.00770025 0.0077992  0.007536\n",
            " 0.00870549 0.00717369 0.00744747 0.00825853 0.00802295 0.00742147\n",
            " 0.00707195 0.00743077 0.00827387 0.00805128 0.00808253 0.00789529\n",
            " 0.00762278 0.00769768 0.00783361 0.00785466 0.00769155 0.00829025\n",
            " 0.0080389  0.00824371 0.00803453 0.007808   0.00812774 0.00790186\n",
            " 0.00803084 0.00734907 0.0072067  0.00739729 0.00877008 0.00763129\n",
            " 0.00824674 0.00768775 0.00723501 0.00760793 0.0082252  0.00833443\n",
            " 0.0079906  0.00775657 0.00799972 0.00757066 0.00751612 0.00721304\n",
            " 0.00726312 0.00730189 0.00755075 0.00829403 0.00777673 0.007787\n",
            " 0.00768325 0.0081652  0.00750713 0.00760562 0.00800111 0.00778991\n",
            " 0.00821048 0.00813209 0.00767239 0.00842456 0.00790222 0.00751437\n",
            " 0.00789996 0.00755009 0.00721819 0.00832501 0.00765466 0.008571\n",
            " 0.00843915 0.00767957 0.0080774  0.00801731 0.00788372 0.00759925\n",
            " 0.00851206 0.00756104 0.00779854 0.00806561 0.00748635 0.00810449\n",
            " 0.00841313 0.00825789 0.00806616 0.00796165 0.00828359 0.00803106\n",
            " 0.00766768 0.00783401 0.00813485 0.00778268 0.00758758 0.00736071\n",
            " 0.00857986 0.00736753 0.00768098 0.00746612 0.00721952 0.00779219\n",
            " 0.00743508 0.00751586 0.00753898 0.00750381 0.00728353 0.0073433\n",
            " 0.00786989 0.00809444 0.0082984  0.00833375 0.00806689 0.00737611\n",
            " 0.00791827 0.0076779  0.00780847 0.00821115 0.0076827  0.00815824\n",
            " 0.00753455 0.00736879], shape=(128,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLtzei0kRktM",
        "colab_type": "text"
      },
      "source": [
        "# BRC Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBZllHp6Rmn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_h = 512\n",
        "batch_size = 128\n",
        "\n",
        "def initialize_brc_parameters(n_h, batch_size, vocab_size):\n",
        "  brc_parameter_dict = {}\n",
        "\n",
        "  brc_parameter_dict[\"W_c\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 1)(shape = (n_h, batch_size)))\n",
        "  brc_parameter_dict[\"W_a\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 2)(shape = (n_h, batch_size)))\n",
        "  brc_parameter_dict[\"U_c\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 3)(shape = (n_h, vocab_size)))\n",
        "  brc_parameter_dict[\"U_a\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 4)(shape = (n_h, vocab_size)))\n",
        "  brc_parameter_dict[\"U_x\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 4)(shape = (n_h, vocab_size)))\n",
        "  brc_parameter_dict[\"b_a\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 5)(shape=[ n_h, 1]))\n",
        "  brc_parameter_dict[\"b_c\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 6)(shape=[ n_h, 1]))\n",
        "  brc_parameter_dict[\"W_o\"] = tf.Variable(tf.initializers.glorot_uniform(seed = 7)(shape=[n_h, vocab_size]))\n",
        "  brc_parameter_dict[\"b_o\"] = tf.Variable(tf.initializers.glorot_uniform(seed = 8)(shape=[1, vocab_size]))\n",
        "\n",
        "  return brc_parameter_dict;"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF6F8O2qRnTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "291fef20-61c5-4c97-cff4-36501fb95bb6"
      },
      "source": [
        "brc_parameter_dict = initialize_brc_parameters(n_h = 512, batch_size=128, vocab_size=vocab_size)\n",
        "for param_name, param_val in brc_parameter_dict.items():\n",
        "  print(\"param_name: {} | shape: {}\".format(param_name, str(param_val.shape)))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "param_name: W_c | shape: (512, 128)\n",
            "param_name: W_a | shape: (512, 128)\n",
            "param_name: U_c | shape: (512, 68)\n",
            "param_name: U_a | shape: (512, 68)\n",
            "param_name: U_x | shape: (512, 68)\n",
            "param_name: b_a | shape: (512, 1)\n",
            "param_name: b_c | shape: (512, 1)\n",
            "param_name: W_o | shape: (512, 68)\n",
            "param_name: b_o | shape: (1, 68)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skkcDIIJnjgK",
        "colab_type": "text"
      },
      "source": [
        "BRC forward compute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIJb2Kurni45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def brc_forward_compute(x_t, parameter_dict, h_prev, brc_ones_tensor):\n",
        "\n",
        "  #update gate\n",
        "  tmp_at = tf.add(tf.matmul(a = brc_parameter_dict[\"U_a\"], b = x_t, transpose_b= True) , tf.multiply(brc_parameter_dict[\"W_a\"], h_prev))\n",
        "  A_t = tf.add(brc_ones_tensor, tf.keras.activations.tanh(tmp_at))\n",
        "\n",
        "  #Reset gate\n",
        "  tmp_ct = tf.add(tf.matmul(a = brc_parameter_dict[\"U_c\"],b = x_t, transpose_b = True) , tf.multiply(brc_parameter_dict[\"W_c\"], h_prev))\n",
        "  C_t = tf.keras.activations.sigmoid(tmp_ct)\n",
        "\n",
        "  #Current cell value\n",
        "  tmp_current_val = tf.add(tf.matmul(a=brc_parameter_dict[\"U_x\"], b=x_t, transpose_b=True) , tf.multiply(A_t, h_prev))\n",
        "  H_t = tf.add(tf.multiply(C_t, h_prev) , tf.multiply((1-C_t), tf.keras.activations.tanh(tmp_current_val)))\n",
        "\n",
        "  #Output of cell\n",
        "  logits = tf.matmul(tf.transpose(H_t), parameter_dict[\"W_o\"] ) + parameter_dict[\"b_o\"]\n",
        "  softmax_output = tf.nn.softmax(logits,axis = 0)\n",
        "\n",
        "  return [A_t, C_t, H_t, logits, softmax_output];\n",
        "\n"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRuXzvZunY1i",
        "colab_type": "text"
      },
      "source": [
        "Sanity Check on sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ukel0H63YuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[128, vocab_size]))\n",
        "h_prev = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[512, 128]))"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ag8kCGrRnZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "c585f727-c272-4149-99f5-8598e5f7fe38"
      },
      "source": [
        "A_t, C_t, H_t, logits, softmax_output = brc_forward_compute(x_t, parameter_dict, h_prev)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-04f403128f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrc_forward_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: tf__brc_forward_compute() missing 1 required positional argument: 'brc_ones_tensor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAwH-MpM0VL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "19a46e01-5d43-497d-c632-7839795b2ae3"
      },
      "source": [
        "softmax_output[1,:]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(68,), dtype=float32, numpy=\n",
              "array([0.00803658, 0.00850225, 0.00673646, 0.00723308, 0.00839005,\n",
              "       0.00740324, 0.00682028, 0.00783177, 0.0078986 , 0.00750549,\n",
              "       0.0082809 , 0.00847614, 0.00735491, 0.00779753, 0.00873234,\n",
              "       0.00849496, 0.00663494, 0.00790718, 0.00792656, 0.0090681 ,\n",
              "       0.00705698, 0.00754907, 0.00646358, 0.00783225, 0.00817844,\n",
              "       0.00661802, 0.00695915, 0.00730259, 0.0083609 , 0.00756912,\n",
              "       0.00746488, 0.00724498, 0.00815309, 0.00829601, 0.00745946,\n",
              "       0.00778952, 0.0078167 , 0.00747664, 0.00710692, 0.00745986,\n",
              "       0.00799013, 0.00698474, 0.00657904, 0.00723013, 0.00755678,\n",
              "       0.00756149, 0.007815  , 0.00919298, 0.00783879, 0.00755976,\n",
              "       0.00807544, 0.00828158, 0.00854651, 0.00739413, 0.00763806,\n",
              "       0.00797055, 0.00790042, 0.00809043, 0.00906261, 0.00804481,\n",
              "       0.00767838, 0.00786132, 0.00682665, 0.00720295, 0.00783846,\n",
              "       0.00962132, 0.00705957, 0.00698116], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lafhj7WG2A5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def compute_loss_per_time_step(lbl_batch, logits):\n",
        "  #print(lbl_batch.shape)\n",
        "  #print(logits.shape)\n",
        "  loss_per_time_step = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = lbl_batch, logits = logits))\n",
        "  return loss_per_time_step;"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVk9zz7URncl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def brc_one_train_step(x_batch_train, val_data, h_prev, time_steps, optimizer, train_acc_metric, \n",
        "                       parameter_dict, logits, out_one_time_step, brc_ones_tensor):\n",
        "\n",
        "  trainable_parameter_names = []\n",
        "  trainable_parameter_values = []\n",
        "  for key, val in parameter_dict.items():\n",
        "    trainable_parameter_names.append(key)\n",
        "    trainable_parameter_values.append(val)\n",
        "  \n",
        "  loss_per_batch = tf.TensorArray(tf.float32, size=200)\n",
        "  with tf.GradientTape() as tape:\n",
        "    for time_step in tf.range(time_steps-1):\n",
        "          \n",
        "      x_t = x_batch_train[:, time_step, :]\n",
        "      #print(\"shape of each time slice: {} \".format(x_t.shape))\n",
        "      lbl_batch = val_data[:, time_step+1]\n",
        "      #print(\"labels shape: {}\".format(lbl_batch.shape))\n",
        "      A_t, C_t, H_t, logits, softmax_output = brc_forward_compute(x_t, parameter_dict, h_prev, brc_ones_tensor)\n",
        "      loss_per_time_step = compute_loss_per_time_step(lbl_batch = lbl_batch, logits=logits)\n",
        "      # loss_per_batch.append(loss_per_time_step)\n",
        "      h_prev = H_t\n",
        "\n",
        "      loss_per_batch = loss_per_batch.write(time_step, loss_per_time_step)\n",
        "      train_acc_metric(lbl_batch, logits)\n",
        "\n",
        "    avg_loss = tf.math.reduce_mean(loss_per_batch.stack())\n",
        "  # # # weight, bias vector updates\n",
        "\n",
        "  grads = tape.gradient(avg_loss, trainable_parameter_values)\n",
        "\n",
        "  optimizer.apply_gradients(zip(grads, trainable_parameter_values))\n",
        "  #grads = tape.gradient(avg_loss, (w_hh1, w_xh1, b_h1, w_ho1, b_o1))\n",
        "  #opt.apply_gradients(zip(grads, (w_hh1, w_xh1, b_h1, w_ho1, b_o1)))\n",
        "  # print(\"Average loss: {}\".format(avg_error))\n",
        "  train_acc = train_acc_metric.result()\n",
        "  return logits, out_one_time_step, h_prev, avg_loss, train_acc"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE1k7EB3y34q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create batches of data\n",
        "# setting drop remainder to true would omit 25549 % 128 = 77 examples from training\n",
        "# but this is important as batchsize is used as one of the dimensions inside weight matrices and weight dimensions must not change on the same data\n",
        "batched_vocab_data = data.batch(batch_size=128,drop_remainder=True)\n",
        "batched_onehotencoded_data = new_data.batch(batch_size=128, drop_remainder=True)\n",
        "# Instantiate an optimizer.\n",
        "optimizer = keras.optimizers.Adam(learning_rate=   1 * 1e-3)\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Prepare the metrics.\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "#initilaize parametrrs and epochs\n",
        "epochs = 15\n",
        "parameter_dict = initialize_brc_parameters(512, batch_size, vocab_size)\n",
        "brc_ones_tensor = tf.Variable(initial_value=tf.ones(shape = (n_h, batch_size)))"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5q7z5Tfy3-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BRCModel(epochs,onehotencoded_train_data, vocab_test_data, parameter_dict, vocab_size = vocab_size, time_steps = 200, brc_ones_tensor = brc_ones_tensor ):\n",
        "  train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate = 1.5 * 1e-3)\n",
        "  h_prev = tf.zeros((512,128), dtype=tf.dtypes.float32)\n",
        "  logits = tf.Variable(tf.zeros((128,vocab_size), dtype=tf.dtypes.float32))\n",
        "  out_one_time_step  = tf.Variable(tf.zeros((128,vocab_size), dtype=tf.dtypes.float32))\n",
        "  for e in tf.range(epochs):\n",
        "    start = time.time()\n",
        "    for batch_num, (x_batch_train, val_data) in enumerate(zip(onehotencoded_train_data,vocab_test_data) ):\n",
        "\n",
        "      logits, out_one_time_step, h_prev, avg_loss, train_acc = brc_one_train_step(x_batch_train, val_data, h_prev, time_steps, optimizer, train_acc_metric, parameter_dict, logits, out_one_time_step, brc_ones_tensor)\n",
        "    \n",
        "    # Display metrics at the end of each epoch.\n",
        "    print(\"Epoch: {}/{}, Loss: {} Accuracy: {}\".format(e+1,epochs, avg_loss, (train_acc.numpy()*100)))\n",
        "    train_acc_metric.reset_states()\n",
        "    stop = time.time()\n",
        "    print(\"took {} seconds\\n\".format(stop-start))"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRaVcvqCy37r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "cb9b424c-0064-4e74-bf70-68eab6f2d112"
      },
      "source": [
        "BRCModel(epochs,batched_onehotencoded_data, batched_vocab_data, parameter_dict )"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/15, Loss: 3.1275856494903564 Accuracy: 14.696283638477325\n",
            "took 86.58064579963684 seconds\n",
            "\n",
            "Epoch: 2/15, Loss: 3.076092004776001 Accuracy: 16.12396091222763\n",
            "took 83.32192540168762 seconds\n",
            "\n",
            "Epoch: 3/15, Loss: 3.043930768966675 Accuracy: 16.927820444107056\n",
            "took 83.89748167991638 seconds\n",
            "\n",
            "Epoch: 4/15, Loss: 3.0209500789642334 Accuracy: 17.506995797157288\n",
            "took 84.85212135314941 seconds\n",
            "\n",
            "Epoch: 5/15, Loss: 3.0033252239227295 Accuracy: 17.942985892295837\n",
            "took 84.67544150352478 seconds\n",
            "\n",
            "Epoch: 6/15, Loss: 2.9893276691436768 Accuracy: 18.27520579099655\n",
            "took 86.02694249153137 seconds\n",
            "\n",
            "Epoch: 7/15, Loss: 2.977917432785034 Accuracy: 18.529006838798523\n",
            "took 85.73701024055481 seconds\n",
            "\n",
            "Epoch: 8/15, Loss: 2.968404531478882 Accuracy: 18.74193102121353\n",
            "took 86.31261897087097 seconds\n",
            "\n",
            "Epoch: 9/15, Loss: 2.9603164196014404 Accuracy: 18.922561407089233\n",
            "took 84.81904935836792 seconds\n",
            "\n",
            "Epoch: 10/15, Loss: 2.953324794769287 Accuracy: 19.077308475971222\n",
            "took 84.9548728466034 seconds\n",
            "\n",
            "Epoch: 11/15, Loss: 2.947194814682007 Accuracy: 19.21449601650238\n",
            "took 85.18786025047302 seconds\n",
            "\n",
            "Epoch: 12/15, Loss: 2.9417552947998047 Accuracy: 19.335725903511047\n",
            "took 84.82438707351685 seconds\n",
            "\n",
            "Epoch: 13/15, Loss: 2.9368791580200195 Accuracy: 19.44519579410553\n",
            "took 84.48451066017151 seconds\n",
            "\n",
            "Epoch: 14/15, Loss: 2.932468891143799 Accuracy: 19.53783929347992\n",
            "took 85.64241456985474 seconds\n",
            "\n",
            "Epoch: 15/15, Loss: 2.928450107574463 Accuracy: 19.62049901485443\n",
            "took 88.01852178573608 seconds\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz52QLTuIZrv",
        "colab_type": "text"
      },
      "source": [
        "param_name: W_c | shape: (512, 128)\n",
        "\n",
        "param_name: W_a | shape: (512, 128)\n",
        "\n",
        "param_name: U_c | shape: (512, 68)\n",
        "\n",
        "param_name: U_a | shape: (512, 68)\n",
        "\n",
        "param_name: U_x | shape: (512, 68)\n",
        "\n",
        "param_name: b_a | shape: (512, 1)\n",
        "\n",
        "param_name: b_c | shape: (512, 1)\n",
        "\n",
        "param_name: W_o | shape: (512, 68)\n",
        "\n",
        "param_name: b_o | shape: (1, 68)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9O6n69KRnWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "filename = \"brc_15epochs.pickle\"\n",
        "with open(filename, 'wb') as f:\n",
        "  parameter_list = [brc_parameter_dict[\"W_c\"], brc_parameter_dict[\"W_a\"], brc_parameter_dict[\"U_c\"], brc_parameter_dict[\"U_a\"], \n",
        "                    brc_parameter_dict[\"U_x\"], brc_parameter_dict[\"b_a\"] ,brc_parameter_dict[\"b_c\"], brc_parameter_dict[\"W_o\"], \n",
        "                    brc_parameter_dict[\"b_o\"], h_prev]\n",
        "  pickle.dump(parameter_list, f)"
      ],
      "execution_count": 89,
      "outputs": []
    }
  ]
}