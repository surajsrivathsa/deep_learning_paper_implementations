{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bio-Inspired-Bistable_Recurrent_Cell.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eYowiuRRONxv",
        "mhM-0LZiPf9c",
        "EWIxTROhQp-E"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPod8wpWICs2xBztEYVISb6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajsrivathsa/deep_learning_paper_implementations/blob/master/Bio_Inspired_Bistable_Recurrent_Cell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od63TDJ8Nltv",
        "colab_type": "text"
      },
      "source": [
        "# Bio Inspired Recurrent Cell\n",
        "**For Long lasting memory**\n",
        "\n",
        "paper link: https://arxiv.org/pdf/2006.05252\n",
        "\n",
        "paper discussion link: https://www.youtube.com/watch?v=DLq1DUcMh1Q\n",
        "\n",
        "Credits: Yannic Kilcher (https://www.bitchute.com/video/TLuAfQz5SlKF/ )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYowiuRRONxv",
        "colab_type": "text"
      },
      "source": [
        "# **Tasks**\n",
        "\n",
        "1. Code in a BRC, NBRC and GRU cells\n",
        "\n",
        "2. Compare BRC vs NBRC vs GRU for a simple dataset\n",
        "\n",
        "3. Make notes, Plot graphs\n",
        "\n",
        "4. Analyze advantages and disadvantages of BRC/NBRC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzGuyKBWFMoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import copy\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WskkGq0OySh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6020ae04-9349-4960-86aa-7d57cb025498"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras import initializers\n",
        "import tensorboard\n",
        "import time\n",
        "from datetime import datetime\n",
        "from keras import backend as K\n",
        "from prepare_data import parse_seq\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOVg3XiiPSR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b0952380-ca92-4595-cd55-edcec8277f9d"
      },
      "source": [
        " print(os.getcwd())\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVpXcfFOPbsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "9b264252-37eb-441d-868f-facaadcf726a"
      },
      "source": [
        "path = '.'\n",
        " \n",
        "files = os.listdir(path)\n",
        "for name in files:\n",
        "    print(name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".config\n",
            "brc_15epochs.pickle\n",
            "__pycache__\n",
            "skp.tfrecords\n",
            "skp_vocab\n",
            "prepare_data.py\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhM-0LZiPf9c",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtV-1U35PbvY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "8e6f65a1-f34e-4e89-e501-1f178c211d7b"
      },
      "source": [
        "\n",
        "# this is just a datasets of \"bytes\" (not understandable)\n",
        "data = tf.data.TFRecordDataset(\"skp.tfrecords\")\n",
        "\n",
        "# this maps a parser function that properly interprets the bytes over the dataset\n",
        "# (with fixed sequence length 200)\n",
        "# if you change the sequence length in preprocessing you also need to change it here\n",
        "data = data.map(lambda x: parse_seq(x, 200))\n",
        "\n",
        "# a map from characters to indices\n",
        "vocab = pickle.load(open(\"skp_vocab\", mode=\"rb\"))\n",
        "vocab_size = len(vocab)\n",
        "# inverse mapping: indices to characters\n",
        "ind_to_ch = {ind: ch for (ch, ind) in vocab.items()}\n",
        "\n",
        "print(vocab)\n",
        "print(vocab_size)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 1, 'C': 2, 'l': 3, '!': 4, '?': 5, 'q': 6, 'f': 7, 't': 8, 'J': 9, 'n': 10, ':': 11, 'i': 12, 'r': 13, 'R': 14, 's': 15, ' ': 16, 'v': 17, 'I': 18, 'V': 19, '-': 20, 'Z': 21, 'X': 22, 'z': 23, 'e': 24, 'U': 25, 'F': 26, 'N': 27, '[': 28, 'm': 29, 'S': 30, 'd': 31, 'O': 32, '3': 33, 'a': 34, ']': 35, 'W': 36, 'c': 37, 'k': 38, 'Y': 39, 'L': 40, 'P': 41, 'w': 42, 'B': 43, \"'\": 44, 'E': 45, 'x': 46, 'H': 47, 'M': 48, 'u': 49, ',': 50, 'y': 51, 'h': 52, 'Q': 53, '&': 54, 'G': 55, 'b': 56, 'D': 57, '$': 58, 'K': 59, 'T': 60, 'o': 61, '.': 62, 'g': 63, 'j': 64, ';': 65, 'A': 66, 'p': 67, '<S>': 0}\n",
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnWFxQsoPb1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehotencode(ds):\n",
        "  \n",
        "  new_data = tf.one_hot(indices = ds, depth = vocab_size)\n",
        "  return new_data;\n",
        "\n",
        "new_data = data.map(onehotencode)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CPJDSNSPbzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee1902b5-dbf6-4884-bc05-daa6a50b2d20"
      },
      "source": [
        "cnt = 0\n",
        "counter = 0\n",
        "for element in data:\n",
        "  counter = counter + 1\n",
        "  print(element)\n",
        "  if(counter > 5):\n",
        "    break;"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[ 0 26 12 13 15  8 16  2 12  8 12 23 24 10 11  1 43 24  7 61 13 24 16 42\n",
            " 24 16 67 13 61 37 24 24 31 16 34 10 51 16  7 49 13  8 52 24 13 50 16 52\n",
            " 24 34 13 16 29 24 16 15 67 24 34 38 62  1  1 66  3  3 11  1 30 67 24 34\n",
            " 38 50 16 15 67 24 34 38 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10\n",
            " 11  1 39 61 49 16 34 13 24 16 34  3  3 16 13 24 15 61  3 17 24 31 16 13\n",
            " 34  8 52 24 13 16  8 61 16 31 12 24 16  8 52 34 10 16  8 61 16  7 34 29\n",
            " 12 15 52  5  1  1 66  3  3 11  1 14 24 15 61  3 17 24 31 62 16 13 24 15\n",
            " 61  3 17 24 31 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10 11  1 26\n",
            " 12 13 15  8 50 16 51 61], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0  8 16  2 12  8 12 23 24 10 11  1 26 12 13 15  8 50 16 51 61 49 16 38\n",
            " 10 61 42 16  2 34 12 49 15 16 48 34 13 37 12 49 15 16 12 15 16 37 52 12\n",
            " 24  7 16 24 10 24 29 51 16  8 61 16  8 52 24 16 67 24 61 67  3 24 62  1\n",
            "  1 66  3  3 11  1 36 24 16 38 10 61 42 44  8 50 16 42 24 16 38 10 61 42\n",
            " 44  8 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10 11  1 40 24  8 16\n",
            " 49 15 16 38 12  3  3 16 52 12 29 50 16 34 10 31 16 42 24 44  3  3 16 52\n",
            " 34 17 24 16 37 61 13 10 16 34  8 16 61 49 13 16 61 42 10 16 67 13 12 37\n",
            " 24 62  1 18 15 44  8 16 34 16 17 24 13 31 12 37  8  5  1  1 66  3  3 11\n",
            "  1 27 61 16 29 61 13 24], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 13 31 12 37  8  5  1  1 66  3  3 11  1 27 61 16 29 61 13 24 16  8 34\n",
            "  3 38 12 10 63 16 61 10 44  8 65 16  3 24  8 16 12  8 16 56 24 16 31 61\n",
            " 10 24 11 16 34 42 34 51 50 16 34 42 34 51  4  1  1 30 24 37 61 10 31 16\n",
            "  2 12  8 12 23 24 10 11  1 32 10 24 16 42 61 13 31 50 16 63 61 61 31 16\n",
            " 37 12  8 12 23 24 10 15 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10\n",
            " 11  1 36 24 16 34 13 24 16 34 37 37 61 49 10  8 24 31 16 67 61 61 13 16\n",
            " 37 12  8 12 23 24 10 15 50 16  8 52 24 16 67 34  8 13 12 37 12 34 10 15\n",
            " 16 63 61 61 31 62  1 36 52 34  8 16 34 49  8 52 61 13 12  8 51 16 15 49\n",
            " 13  7 24 12  8 15 16 61], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 34 49  8 52 61 13 12  8 51 16 15 49 13  7 24 12  8 15 16 61 10 16 42\n",
            " 61 49  3 31 16 13 24  3 12 24 17 24 16 49 15 11 16 12  7 16  8 52 24 51\n",
            "  1 42 61 49  3 31 16 51 12 24  3 31 16 49 15 16 56 49  8 16  8 52 24 16\n",
            " 15 49 67 24 13  7  3 49 12  8 51 50 16 42 52 12  3 24 16 12  8 16 42 24\n",
            " 13 24  1 42 52 61  3 24 15 61 29 24 50 16 42 24 16 29 12 63 52  8 16 63\n",
            " 49 24 15 15 16  8 52 24 51 16 13 24  3 12 24 17 24 31 16 49 15 16 52 49\n",
            " 29 34 10 24  3 51 65  1 56 49  8 16  8 52 24 51 16  8 52 12 10 38 16 42\n",
            " 24 16 34 13 24 16  8 61 61 16 31 24 34 13 11 16  8 52 24 16  3 24 34 10\n",
            " 10 24 15 15 16  8 52 34], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 34 13 11 16  8 52 24 16  3 24 34 10 10 24 15 15 16  8 52 34  8  1 34\n",
            "  7  7  3 12 37  8 15 16 49 15 50 16  8 52 24 16 61 56 64 24 37  8 16 61\n",
            "  7 16 61 49 13 16 29 12 15 24 13 51 50 16 12 15 16 34 15 16 34 10  1 12\n",
            " 10 17 24 10  8 61 13 51 16  8 61 16 67 34 13  8 12 37 49  3 34 13 12 15\n",
            " 24 16  8 52 24 12 13 16 34 56 49 10 31 34 10 37 24 65 16 61 49 13  1 15\n",
            " 49  7  7 24 13 34 10 37 24 16 12 15 16 34 16 63 34 12 10 16  8 61 16  8\n",
            " 52 24 29 16 40 24  8 16 49 15 16 13 24 17 24 10 63 24 16  8 52 12 15 16\n",
            " 42 12  8 52  1 61 49 13 16 67 12 38 24 15 50 16 24 13 24 16 42 24 16 56\n",
            " 24 37 61 29 24 16 13 34], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 24 15 50 16 24 13 24 16 42 24 16 56 24 37 61 29 24 16 13 34 38 24 15\n",
            " 11 16  7 61 13 16  8 52 24 16 63 61 31 15 16 38 10 61 42 16 18  1 15 67\n",
            " 24 34 38 16  8 52 12 15 16 12 10 16 52 49 10 63 24 13 16  7 61 13 16 56\n",
            " 13 24 34 31 50 16 10 61  8 16 12 10 16  8 52 12 13 15  8 16  7 61 13 16\n",
            " 13 24 17 24 10 63 24 62  1  1 30 24 37 61 10 31 16  2 12  8 12 23 24 10\n",
            " 11  1 36 61 49  3 31 16 51 61 49 16 67 13 61 37 24 24 31 16 24 15 67 24\n",
            " 37 12 34  3  3 51 16 34 63 34 12 10 15  8 16  2 34 12 49 15 16 48 34 13\n",
            " 37 12 49 15  5  1  1 66  3  3 11  1 66 63 34 12 10 15  8 16 52 12 29 16\n",
            "  7 12 13 15  8 11 16 52], shape=(200,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t57QtvIAQDws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "733ae633-528a-45c9-f198-5d1afa933c4e"
      },
      "source": [
        "cnt = 0\n",
        "for element in data:\n",
        "  cnt = cnt+1\n",
        "print(cnt)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWIxTROhQp-E",
        "colab_type": "text"
      },
      "source": [
        "# GRU Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80moQlnxQDz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters(n_h, vocab_size):\n",
        "  parameter_dict = {}\n",
        "\n",
        "  parameter_dict[\"W_h\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[n_h, n_h + vocab_size]))\n",
        "  print(\"W_h: \" + str(parameter_dict[\"W_h\"].shape))\n",
        "  parameter_dict[\"b_h\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 2)(shape=[ n_h, 1]))\n",
        "  print(\"b_h: \" + str(parameter_dict[\"b_h\"].shape))\n",
        "\n",
        "\n",
        "  parameter_dict[\"W_u\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 3)(shape=[n_h, n_h + vocab_size]))\n",
        "  print(\"W_u: \" + str(parameter_dict[\"W_u\"].shape))\n",
        "  parameter_dict[\"b_u\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 2)(shape=[ n_h, 1]))\n",
        "  print(\"b_u: \" + str(parameter_dict[\"b_u\"].shape))\n",
        "\n",
        "  parameter_dict[\"W_r\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 4)(shape=[n_h, n_h + vocab_size]))\n",
        "  print(\"W_r: \" + str(parameter_dict[\"W_r\"].shape))\n",
        "  parameter_dict[\"b_r\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 5)(shape=[ n_h, 1]))\n",
        "  print(\"b_r: \" + str(parameter_dict[\"b_r\"].shape))\n",
        "\n",
        "  parameter_dict[\"W_o\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 7)(shape=[n_h, vocab_size]))\n",
        "  print(\"W_o: \" + str(parameter_dict[\"W_o\"].shape))\n",
        "  parameter_dict[\"b_o\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 6)(shape=[ 1, vocab_size]))\n",
        "  print(\"b_o: \" + str(parameter_dict[\"b_o\"].shape))\n",
        "  \n",
        "  return parameter_dict;"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlwEEIUUQD2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ones_tensor = tf.Variable(tf.ones(shape =[512, 128], dtype=tf.dtypes.float32))\n",
        "\n",
        "def gru_forward_compute(x_t, parameter_dict, h_prev):\n",
        "\n",
        "  stacked_input = tf.concat([h_prev, tf.transpose(x_t)], axis = 0)\n",
        "  \n",
        "  update_gate = tf.nn.sigmoid(tf.matmul(parameter_dict[\"W_u\"], stacked_input ) + parameter_dict[\"b_u\"])\n",
        "  #print(update_gate.shape)\n",
        "\n",
        "  reset_gate = tf.nn.sigmoid(tf.matmul(parameter_dict[\"W_r\"], stacked_input ) + parameter_dict[\"b_r\"])\n",
        "  #print(reset_gate.shape)\n",
        "\n",
        "  hadamard_product = tf.multiply(reset_gate, h_prev)\n",
        "  stacked_cell_input = tf.concat([hadamard_product, tf.transpose(x_t)], axis = 0)\n",
        "  h_tilde = tf.nn.tanh(tf.matmul(parameter_dict[\"W_h\"], stacked_cell_input ) + parameter_dict[\"b_h\"])\n",
        "\n",
        "  \n",
        "  h = tf.multiply(update_gate, h_tilde) + tf.multiply(tf.subtract(ones_tensor, update_gate), h_prev)\n",
        "\n",
        "  logits = tf.matmul(tf.transpose(h), parameter_dict[\"W_o\"] ) + parameter_dict[\"b_o\"]\n",
        "  softmax_output = tf.nn.softmax(logits,axis = 0)\n",
        "\n",
        "  return [update_gate, reset_gate, h, logits, softmax_output];"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiNwso5CQ5dm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "b20d0c80-bfb5-4011-9c5e-cae4b214d9e8"
      },
      "source": [
        "parameter_dict = initialize_parameters(n_h=512, vocab_size=vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_h: (512, 580)\n",
            "b_h: (512, 1)\n",
            "W_u: (512, 580)\n",
            "b_u: (512, 1)\n",
            "W_r: (512, 580)\n",
            "b_r: (512, 1)\n",
            "W_o: (512, 68)\n",
            "b_o: (1, 68)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGOrK_XpQ5gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[128, vocab_size]))\n",
        "h_prev = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[512, 128]))\n",
        "update_gate, reset_gate, h, logits, softmax_output = gru_forward_compute(x_t, parameter_dict, h_prev)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Xfiqc0RYZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ca3d568-c4f5-4aba-dd47-5c4766467fdc"
      },
      "source": [
        "tf.shape(softmax_output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([128,  68], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dKUl1m1RFyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "fdab945d-30bf-4ab8-d942-648fb73b2ea7"
      },
      "source": [
        "#print(update_gate)\n",
        "#print(h)\n",
        "print(tf.reduce_sum(softmax_output[:, 2]))\n",
        "print(softmax_output[:, 2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[0.00768709 0.00754427 0.00781152 0.00689983 0.00797018 0.00783288\n",
            " 0.00819303 0.00695316 0.00779048 0.00770025 0.0077992  0.007536\n",
            " 0.00870549 0.00717369 0.00744747 0.00825853 0.00802295 0.00742147\n",
            " 0.00707195 0.00743077 0.00827387 0.00805128 0.00808253 0.00789529\n",
            " 0.00762278 0.00769768 0.00783361 0.00785466 0.00769155 0.00829025\n",
            " 0.0080389  0.00824371 0.00803453 0.007808   0.00812774 0.00790186\n",
            " 0.00803084 0.00734907 0.0072067  0.00739729 0.00877008 0.00763129\n",
            " 0.00824674 0.00768775 0.00723501 0.00760793 0.0082252  0.00833443\n",
            " 0.0079906  0.00775657 0.00799972 0.00757066 0.00751612 0.00721304\n",
            " 0.00726312 0.00730189 0.00755075 0.00829403 0.00777673 0.007787\n",
            " 0.00768325 0.0081652  0.00750713 0.00760562 0.00800111 0.00778991\n",
            " 0.00821048 0.00813209 0.00767239 0.00842456 0.00790222 0.00751437\n",
            " 0.00789996 0.00755009 0.00721819 0.00832501 0.00765466 0.008571\n",
            " 0.00843915 0.00767957 0.0080774  0.00801731 0.00788372 0.00759925\n",
            " 0.00851206 0.00756104 0.00779854 0.00806561 0.00748635 0.00810449\n",
            " 0.00841313 0.00825789 0.00806616 0.00796165 0.00828359 0.00803106\n",
            " 0.00766768 0.00783401 0.00813485 0.00778268 0.00758758 0.00736071\n",
            " 0.00857986 0.00736753 0.00768098 0.00746612 0.00721952 0.00779219\n",
            " 0.00743508 0.00751586 0.00753898 0.00750381 0.00728353 0.0073433\n",
            " 0.00786989 0.00809444 0.0082984  0.00833375 0.00806689 0.00737611\n",
            " 0.00791827 0.0076779  0.00780847 0.00821115 0.0076827  0.00815824\n",
            " 0.00753455 0.00736879], shape=(128,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLtzei0kRktM",
        "colab_type": "text"
      },
      "source": [
        "# BRC Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBZllHp6Rmn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_h = 512\n",
        "batch_size = 128\n",
        "\n",
        "def initialize_brc_parameters(n_h, batch_size, vocab_size):\n",
        "  brc_parameter_dict = {}\n",
        "\n",
        "  brc_parameter_dict[\"W_c\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 1)(shape = (n_h, batch_size)))\n",
        "  brc_parameter_dict[\"W_a\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 2)(shape = (n_h, batch_size)))\n",
        "  brc_parameter_dict[\"U_c\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 3)(shape = (n_h, vocab_size)))\n",
        "  brc_parameter_dict[\"U_a\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 4)(shape = (n_h, vocab_size)))\n",
        "  brc_parameter_dict[\"U_x\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 4)(shape = (n_h, vocab_size)))\n",
        "  brc_parameter_dict[\"b_a\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 5)(shape=[ n_h, 1]))\n",
        "  brc_parameter_dict[\"b_c\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 6)(shape=[ n_h, 1]))\n",
        "  brc_parameter_dict[\"W_o\"] = tf.Variable(tf.initializers.glorot_uniform(seed = 7)(shape=[n_h, vocab_size]))\n",
        "  brc_parameter_dict[\"b_o\"] = tf.Variable(tf.initializers.glorot_uniform(seed = 8)(shape=[1, vocab_size]))\n",
        "\n",
        "  return brc_parameter_dict;"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF6F8O2qRnTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "4b7ded27-8e7a-4d6e-8295-0df2d40665b5"
      },
      "source": [
        "brc_parameter_dict = initialize_brc_parameters(n_h = 512, batch_size=128, vocab_size=vocab_size)\n",
        "for param_name, param_val in brc_parameter_dict.items():\n",
        "  print(\"param_name: {} | shape: {}\".format(param_name, str(param_val.shape)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "param_name: W_c | shape: (512, 128)\n",
            "param_name: W_a | shape: (512, 128)\n",
            "param_name: U_c | shape: (512, 68)\n",
            "param_name: U_a | shape: (512, 68)\n",
            "param_name: U_x | shape: (512, 68)\n",
            "param_name: b_a | shape: (512, 1)\n",
            "param_name: b_c | shape: (512, 1)\n",
            "param_name: W_o | shape: (512, 68)\n",
            "param_name: b_o | shape: (1, 68)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skkcDIIJnjgK",
        "colab_type": "text"
      },
      "source": [
        "BRC forward compute"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIJb2Kurni45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def brc_forward_compute(x_t, parameter_dict, h_prev, brc_ones_tensor):\n",
        "\n",
        "  #update gate\n",
        "  tmp_at = tf.add(tf.matmul(a = brc_parameter_dict[\"U_a\"], b = x_t, transpose_b= True) , tf.multiply(brc_parameter_dict[\"W_a\"], h_prev))\n",
        "  A_t = tf.add(brc_ones_tensor, tf.keras.activations.tanh(tmp_at))\n",
        "\n",
        "  #Reset gate\n",
        "  tmp_ct = tf.add(tf.matmul(a = brc_parameter_dict[\"U_c\"],b = x_t, transpose_b = True) , tf.multiply(brc_parameter_dict[\"W_c\"], h_prev))\n",
        "  C_t = tf.keras.activations.sigmoid(tmp_ct)\n",
        "\n",
        "  #Current cell value\n",
        "  tmp_current_val = tf.add(tf.matmul(a=brc_parameter_dict[\"U_x\"], b=x_t, transpose_b=True) , tf.multiply(A_t, h_prev))\n",
        "  H_t = tf.add(tf.multiply(C_t, h_prev) , tf.multiply((1-C_t), tf.keras.activations.tanh(tmp_current_val)))\n",
        "\n",
        "  #Output of cell\n",
        "  logits = tf.matmul(tf.transpose(H_t), parameter_dict[\"W_o\"] ) + parameter_dict[\"b_o\"]\n",
        "  softmax_output = tf.nn.softmax(logits,axis = 0)\n",
        "\n",
        "  return [A_t, C_t, H_t, logits, softmax_output];\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRuXzvZunY1i",
        "colab_type": "text"
      },
      "source": [
        "Sanity Check on sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ukel0H63YuD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[128, vocab_size]))\n",
        "h_prev = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[512, 128]))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ag8kCGrRnZI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "c585f727-c272-4149-99f5-8598e5f7fe38"
      },
      "source": [
        "A_t, C_t, H_t, logits, softmax_output = brc_forward_compute(x_t, parameter_dict, h_prev)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-70-04f403128f66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mA_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msoftmax_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbrc_forward_compute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_prev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    625\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    626\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 627\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    628\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    504\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    505\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 506\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2444\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2445\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2446\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2447\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2667\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2669\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: tf__brc_forward_compute() missing 1 required positional argument: 'brc_ones_tensor'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pAwH-MpM0VL1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "19a46e01-5d43-497d-c632-7839795b2ae3"
      },
      "source": [
        "softmax_output[1,:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(68,), dtype=float32, numpy=\n",
              "array([0.00803658, 0.00850225, 0.00673646, 0.00723308, 0.00839005,\n",
              "       0.00740324, 0.00682028, 0.00783177, 0.0078986 , 0.00750549,\n",
              "       0.0082809 , 0.00847614, 0.00735491, 0.00779753, 0.00873234,\n",
              "       0.00849496, 0.00663494, 0.00790718, 0.00792656, 0.0090681 ,\n",
              "       0.00705698, 0.00754907, 0.00646358, 0.00783225, 0.00817844,\n",
              "       0.00661802, 0.00695915, 0.00730259, 0.0083609 , 0.00756912,\n",
              "       0.00746488, 0.00724498, 0.00815309, 0.00829601, 0.00745946,\n",
              "       0.00778952, 0.0078167 , 0.00747664, 0.00710692, 0.00745986,\n",
              "       0.00799013, 0.00698474, 0.00657904, 0.00723013, 0.00755678,\n",
              "       0.00756149, 0.007815  , 0.00919298, 0.00783879, 0.00755976,\n",
              "       0.00807544, 0.00828158, 0.00854651, 0.00739413, 0.00763806,\n",
              "       0.00797055, 0.00790042, 0.00809043, 0.00906261, 0.00804481,\n",
              "       0.00767838, 0.00786132, 0.00682665, 0.00720295, 0.00783846,\n",
              "       0.00962132, 0.00705957, 0.00698116], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lafhj7WG2A5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def compute_loss_per_time_step(lbl_batch, logits):\n",
        "  #print(lbl_batch.shape)\n",
        "  #print(logits.shape)\n",
        "  loss_per_time_step = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(labels = lbl_batch, logits = logits))\n",
        "  return loss_per_time_step;"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVk9zz7URncl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def brc_one_train_step(x_batch_train, val_data, h_prev, time_steps, optimizer, train_acc_metric, \n",
        "                       parameter_dict, logits, out_one_time_step, brc_ones_tensor):\n",
        "\n",
        "  trainable_parameter_names = []\n",
        "  trainable_parameter_values = []\n",
        "  for key, val in parameter_dict.items():\n",
        "    trainable_parameter_names.append(key)\n",
        "    trainable_parameter_values.append(val)\n",
        "  \n",
        "  loss_per_batch = tf.TensorArray(tf.float32, size=200)\n",
        "  with tf.GradientTape() as tape:\n",
        "    for time_step in tf.range(time_steps-1):\n",
        "          \n",
        "      x_t = x_batch_train[:, time_step, :]\n",
        "      #print(\"shape of each time slice: {} \".format(x_t.shape))\n",
        "      lbl_batch = val_data[:, time_step+1]\n",
        "      #print(\"labels shape: {}\".format(lbl_batch.shape))\n",
        "      A_t, C_t, H_t, logits, softmax_output = brc_forward_compute(x_t, parameter_dict, h_prev, brc_ones_tensor)\n",
        "      loss_per_time_step = compute_loss_per_time_step(lbl_batch = lbl_batch, logits=logits)\n",
        "      # loss_per_batch.append(loss_per_time_step)\n",
        "      h_prev = H_t\n",
        "\n",
        "      loss_per_batch = loss_per_batch.write(time_step, loss_per_time_step)\n",
        "      train_acc_metric(lbl_batch, logits)\n",
        "\n",
        "    avg_loss = tf.math.reduce_mean(loss_per_batch.stack())\n",
        "  # # # weight, bias vector updates\n",
        "\n",
        "  grads = tape.gradient(avg_loss, trainable_parameter_values)\n",
        "\n",
        "  optimizer.apply_gradients(zip(grads, trainable_parameter_values))\n",
        "  #grads = tape.gradient(avg_loss, (w_hh1, w_xh1, b_h1, w_ho1, b_o1))\n",
        "  #opt.apply_gradients(zip(grads, (w_hh1, w_xh1, b_h1, w_ho1, b_o1)))\n",
        "  # print(\"Average loss: {}\".format(avg_error))\n",
        "  train_acc = train_acc_metric.result()\n",
        "  return logits, out_one_time_step, h_prev, avg_loss, train_acc"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RE1k7EB3y34q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create batches of data\n",
        "# setting drop remainder to true would omit 25549 % 128 = 77 examples from training\n",
        "# but this is important as batchsize is used as one of the dimensions inside weight matrices and weight dimensions must not change on the same data\n",
        "batched_vocab_data = data.batch(batch_size=128,drop_remainder=True)\n",
        "batched_onehotencoded_data = new_data.batch(batch_size=128, drop_remainder=True)\n",
        "# Instantiate an optimizer.\n",
        "optimizer = keras.optimizers.Adam(learning_rate=   1 * 1e-3)\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Prepare the metrics.\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "val_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "#initilaize parametrrs and epochs\n",
        "epochs = 15\n",
        "parameter_dict = initialize_brc_parameters(512, batch_size, vocab_size)\n",
        "brc_ones_tensor = tf.Variable(initial_value=tf.ones(shape = (n_h, batch_size)))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5q7z5Tfy3-c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def BRCModel(epochs,onehotencoded_train_data, vocab_test_data, parameter_dict, vocab_size = vocab_size, time_steps = 200, brc_ones_tensor = brc_ones_tensor ):\n",
        "  train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate = 1.5 * 1e-3)\n",
        "  h_prev = tf.zeros((512,128), dtype=tf.dtypes.float32)\n",
        "  logits = tf.Variable(tf.zeros((128,vocab_size), dtype=tf.dtypes.float32))\n",
        "  out_one_time_step  = tf.Variable(tf.zeros((128,vocab_size), dtype=tf.dtypes.float32))\n",
        "  for e in tf.range(epochs):\n",
        "    start = time.time()\n",
        "    for batch_num, (x_batch_train, val_data) in enumerate(zip(onehotencoded_train_data,vocab_test_data) ):\n",
        "\n",
        "      logits, out_one_time_step, h_prev, avg_loss, train_acc = brc_one_train_step(x_batch_train, val_data, h_prev, time_steps, optimizer, train_acc_metric, parameter_dict, logits, out_one_time_step, brc_ones_tensor)\n",
        "    \n",
        "    # Display metrics at the end of each epoch.\n",
        "    print(\"Epoch: {}/{}, Loss: {} Accuracy: {}\".format(e+1,epochs, avg_loss, (train_acc.numpy()*100)))\n",
        "    train_acc_metric.reset_states()\n",
        "    stop = time.time()\n",
        "    print(\"took {} seconds\\n\".format(stop-start))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRaVcvqCy37r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        },
        "outputId": "cb9b424c-0064-4e74-bf70-68eab6f2d112"
      },
      "source": [
        "BRCModel(epochs,batched_onehotencoded_data, batched_vocab_data, parameter_dict )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/15, Loss: 3.1275856494903564 Accuracy: 14.696283638477325\n",
            "took 86.58064579963684 seconds\n",
            "\n",
            "Epoch: 2/15, Loss: 3.076092004776001 Accuracy: 16.12396091222763\n",
            "took 83.32192540168762 seconds\n",
            "\n",
            "Epoch: 3/15, Loss: 3.043930768966675 Accuracy: 16.927820444107056\n",
            "took 83.89748167991638 seconds\n",
            "\n",
            "Epoch: 4/15, Loss: 3.0209500789642334 Accuracy: 17.506995797157288\n",
            "took 84.85212135314941 seconds\n",
            "\n",
            "Epoch: 5/15, Loss: 3.0033252239227295 Accuracy: 17.942985892295837\n",
            "took 84.67544150352478 seconds\n",
            "\n",
            "Epoch: 6/15, Loss: 2.9893276691436768 Accuracy: 18.27520579099655\n",
            "took 86.02694249153137 seconds\n",
            "\n",
            "Epoch: 7/15, Loss: 2.977917432785034 Accuracy: 18.529006838798523\n",
            "took 85.73701024055481 seconds\n",
            "\n",
            "Epoch: 8/15, Loss: 2.968404531478882 Accuracy: 18.74193102121353\n",
            "took 86.31261897087097 seconds\n",
            "\n",
            "Epoch: 9/15, Loss: 2.9603164196014404 Accuracy: 18.922561407089233\n",
            "took 84.81904935836792 seconds\n",
            "\n",
            "Epoch: 10/15, Loss: 2.953324794769287 Accuracy: 19.077308475971222\n",
            "took 84.9548728466034 seconds\n",
            "\n",
            "Epoch: 11/15, Loss: 2.947194814682007 Accuracy: 19.21449601650238\n",
            "took 85.18786025047302 seconds\n",
            "\n",
            "Epoch: 12/15, Loss: 2.9417552947998047 Accuracy: 19.335725903511047\n",
            "took 84.82438707351685 seconds\n",
            "\n",
            "Epoch: 13/15, Loss: 2.9368791580200195 Accuracy: 19.44519579410553\n",
            "took 84.48451066017151 seconds\n",
            "\n",
            "Epoch: 14/15, Loss: 2.932468891143799 Accuracy: 19.53783929347992\n",
            "took 85.64241456985474 seconds\n",
            "\n",
            "Epoch: 15/15, Loss: 2.928450107574463 Accuracy: 19.62049901485443\n",
            "took 88.01852178573608 seconds\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fz52QLTuIZrv",
        "colab_type": "text"
      },
      "source": [
        "param_name: W_c | shape: (512, 128)\n",
        "\n",
        "param_name: W_a | shape: (512, 128)\n",
        "\n",
        "param_name: U_c | shape: (512, 68)\n",
        "\n",
        "param_name: U_a | shape: (512, 68)\n",
        "\n",
        "param_name: U_x | shape: (512, 68)\n",
        "\n",
        "param_name: b_a | shape: (512, 1)\n",
        "\n",
        "param_name: b_c | shape: (512, 1)\n",
        "\n",
        "param_name: W_o | shape: (512, 68)\n",
        "\n",
        "param_name: b_o | shape: (1, 68)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9O6n69KRnWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "filename = \"brc_15epochs.pickle\"\n",
        "with open(filename, 'wb') as f:\n",
        "  parameter_list = [brc_parameter_dict[\"W_c\"], brc_parameter_dict[\"W_a\"], brc_parameter_dict[\"U_c\"], brc_parameter_dict[\"U_a\"], \n",
        "                    brc_parameter_dict[\"U_x\"], brc_parameter_dict[\"b_a\"] ,brc_parameter_dict[\"b_c\"], brc_parameter_dict[\"W_o\"], \n",
        "                    brc_parameter_dict[\"b_o\"], h_prev]\n",
        "  pickle.dump(parameter_list, f)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lN7FM6MUkPOA",
        "colab_type": "text"
      },
      "source": [
        "Reloading from pickle file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U--kmSrCkSC_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brc_parameter_dict = initialize_brc_parameters(n_h = 512, batch_size=1, vocab_size=vocab_size)\n",
        "\n",
        "h_prev_one_step = tf.zeros((512,1), dtype=tf.dtypes.float32)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBACZg_6kRPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('brc_15epochs.pickle', 'rb') as f:\n",
        "    brc_parameter_dict[\"W_c\"], brc_parameter_dict[\"W_a\"], brc_parameter_dict[\"U_c\"], brc_parameter_dict[\"U_a\"], brc_parameter_dict[\"U_x\"], brc_parameter_dict[\"b_a\"] ,brc_parameter_dict[\"b_c\"], brc_parameter_dict[\"W_o\"], brc_parameter_dict[\"b_o\"], h_prev = pickle.load(f)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-8msixqry5k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "fa35866b-ed4e-4be6-e79b-892ed710f484"
      },
      "source": [
        "for param_name, param_val in brc_parameter_dict.items():\n",
        "  print(\"param_name: {} | shape: {}\".format(param_name, str(param_val.shape)))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "param_name: W_c | shape: (512, 128)\n",
            "param_name: W_a | shape: (512, 128)\n",
            "param_name: U_c | shape: (512, 68)\n",
            "param_name: U_a | shape: (512, 68)\n",
            "param_name: U_x | shape: (512, 68)\n",
            "param_name: b_a | shape: (512, 1)\n",
            "param_name: b_c | shape: (512, 1)\n",
            "param_name: W_o | shape: (512, 68)\n",
            "param_name: b_o | shape: (1, 68)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aawr_37MmAYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ch_to_ind = {ch: ind for (ch, ind) in vocab.items()}\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPjKZ6NzmIxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f91844ac-069d-4628-c0fa-5493ae9f0d1c"
      },
      "source": [
        "start_sequence_ind = ch_to_ind['<S>']\n",
        "start_sequence_onehot_encode = tf.expand_dims(tf.one_hot(indices = start_sequence_ind, depth = vocab_size), 0)\n",
        "print(tf.shape(start_sequence_onehot_encode))\n",
        "max_char_per_line = 200\n",
        "full_stop_in = [\".\"]\n",
        "string = \"\"\n",
        "lines = 5"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([ 1 68], shape=(2,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sd34txIlmMAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "outputId": "01eecb59-6144-4f1b-db0c-b6706aa24015"
      },
      "source": [
        "A_t, C_t, h, logits, out_one_time_step = brc_forward_compute(start_sequence_onehot_encode, brc_parameter_dict, h_prev_one_step, brc_ones_tensor)\n",
        "logits_new = tf.expand_dims(logits[0,:], 0)\n",
        "out_one_time_step_new = tf.keras.activations.softmax(logits_new, axis = 1)\n",
        "print(tf.reduce_sum(out_one_time_step_new))\n",
        "print(logits_new)\n",
        "print(out_one_time_step_new)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.04445613  0.02277217 -0.09893463 -0.05903392 -0.21298097 -0.08513761\n",
            "  -0.02971987  0.3296352  -0.2206662   0.17894073 -0.05240424 -0.11207382\n",
            "   0.19026914 -0.06063742  0.28856543 -0.18098368  0.07178744  0.13226956\n",
            "   0.18482935 -0.24555147  0.07727104 -0.2772529  -0.01881694  0.10315073\n",
            "   0.00777204  0.3368064  -0.06707317 -0.15997317 -0.10628754  0.14425433\n",
            "  -0.04614696 -0.20397264  0.01266314 -0.14040865 -0.22999996 -0.20599803\n",
            "   0.08018166  0.25311965 -0.22777742  0.16095291 -0.19134846 -0.04515719\n",
            "  -0.24042912  0.30456308 -0.17251863  0.09253357 -0.05116747 -0.10756056\n",
            "  -0.04040495 -0.19108328  0.1059191  -0.26592284 -0.00786913  0.17246129\n",
            "   0.17972106  0.02592861  0.05674303  0.1164491   0.23502126 -0.1119813\n",
            "  -0.0086405  -0.2118564  -0.02297675 -0.26260766 -0.28983554  0.25277996\n",
            "  -0.18931557  0.13779117]], shape=(1, 68), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[0.015414   0.01508336 0.01335493 0.01389858 0.01191549 0.01354047\n",
            "  0.01431203 0.02050063 0.01182427 0.0176328  0.01399102 0.01318061\n",
            "  0.01783369 0.01387631 0.01967573 0.01230292 0.0158411  0.01682877\n",
            "  0.01773694 0.01153365 0.0159282  0.01117375 0.01446893 0.0163458\n",
            "  0.0148588  0.02064817 0.01378729 0.01256414 0.01325709 0.01703167\n",
            "  0.01407885 0.01202331 0.01493165 0.01281238 0.01171442 0.01199899\n",
            "  0.01597463 0.01899052 0.01174048 0.01731846 0.01217606 0.01409279\n",
            "  0.01159288 0.01999302 0.01240751 0.01617317 0.01400834 0.01324023\n",
            "  0.01415992 0.01217929 0.01639111 0.01130107 0.0146282  0.01751892\n",
            "  0.01764657 0.01513105 0.01560456 0.01656463 0.01864991 0.01318183\n",
            "  0.01461692 0.0119289  0.01440886 0.0113386  0.01103404 0.01898407\n",
            "  0.01220084 0.01692195]], shape=(1, 68), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_6Tq7QEmiXh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ch_to_ind['.']\n",
        "index_list = list(range(vocab_size))\n",
        "string = \"\""
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RU4uUfyAnCOH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "8b9903fa-989d-4c39-f058-f7f7af6490b7"
      },
      "source": [
        "np_array = out_one_time_step_new.numpy()\n",
        "print(np_array)\n",
        "print(np.shape(np_array))\n",
        "ind = np.random.choice( index_list, p=np_array.flatten())\n",
        "string = string + ind_to_ch[ind]\n",
        "print(string)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.015414   0.01508336 0.01335493 0.01389858 0.01191549 0.01354047\n",
            "  0.01431203 0.02050063 0.01182427 0.0176328  0.01399102 0.01318061\n",
            "  0.01783369 0.01387631 0.01967573 0.01230292 0.0158411  0.01682877\n",
            "  0.01773694 0.01153365 0.0159282  0.01117375 0.01446893 0.0163458\n",
            "  0.0148588  0.02064817 0.01378729 0.01256414 0.01325709 0.01703167\n",
            "  0.01407885 0.01202331 0.01493165 0.01281238 0.01171442 0.01199899\n",
            "  0.01597463 0.01899052 0.01174048 0.01731846 0.01217606 0.01409279\n",
            "  0.01159288 0.01999302 0.01240751 0.01617317 0.01400834 0.01324023\n",
            "  0.01415992 0.01217929 0.01639111 0.01130107 0.0146282  0.01751892\n",
            "  0.01764657 0.01513105 0.01560456 0.01656463 0.01864991 0.01318183\n",
            "  0.01461692 0.0119289  0.01440886 0.0113386  0.01103404 0.01898407\n",
            "  0.01220084 0.01692195]]\n",
            "(1, 68)\n",
            "!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3WkFQsjnCRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e2ddc170-728c-49e6-9c6d-4d1d87e0893c"
      },
      "source": [
        "for line in range(100):\n",
        "  string = \"\"\n",
        "  ind = 0\n",
        "  for i in range(max_char_per_line):\n",
        "    if(i == 0):\n",
        "      A_t, C_t, h, logits, out_one_time_step = brc_forward_compute(start_sequence_onehot_encode, brc_parameter_dict, h_prev_one_step, brc_ones_tensor)\n",
        "      logits_new = tf.expand_dims(logits[0,:], 0)\n",
        "      softmax_output = tf.keras.activations.softmax(logits_new, axis = 1)\n",
        "    else:\n",
        "      next_sequence_onehot_encode = tf.expand_dims(tf.one_hot(indices = ind, depth = vocab_size), 0)\n",
        "      A_t, C_t, h, logits, out_one_time_step = brc_forward_compute(next_sequence_onehot_encode, brc_parameter_dict, h_prev_one_step, brc_ones_tensor)\n",
        "      logits_new = tf.expand_dims(logits[0,:], 0)\n",
        "      softmax_output = tf.keras.activations.softmax(logits_new, axis = 1)\n",
        "\n",
        "    h_prev = h\n",
        "    np_array = softmax_output.numpy()\n",
        "    \n",
        "    ind = np.random.choice( index_list, p=np_array.flatten())\n",
        "\n",
        "    string = string + ind_to_ch[ind]\n",
        "    \n",
        "    if(ind == ch_to_ind[\".\"]):\n",
        "      string = string + \"\\n\";\n",
        "      break;\n",
        "  \n",
        "  print(string)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W]WUv!;YRJ<S>QhAbrat<S>RW<S>OrNS,z[vGB rObC]vgxLs:GEm!Qq?D&.\n",
            "\n",
            "IS.\n",
            "\n",
            "zPPnipeoUx][[<S>'hZtECDvRoTUVMFpNbERp;,WBSprKT;b$kjIgK$QXliLrB$by]v<S>xmpNBJ'&PO<S>h-hY'Fmb$-pshW$Vcfvhyw$:G[VFl-EuZxXPBh3[SnMUBEx.\n",
            "\n",
            "pdj[aO<S>bWU<S>  f:rDon3cNTBm&qrQG3Y;BN]CXp[3X3mkn;3bDDL<S>yNfz ]bThvfUZJpsTN3KUXdTlMc$vY!fH?RHm-U.\n",
            "\n",
            "vWMeuQGSHBuCCB; sskX\n",
            "w:P:Yiduk Ec!iWQEUMECcTi\n",
            "JfymF,FjKKJ-W:,y;rCeVRl<S>:O;ANUcOzk]M\n",
            "O!EX-&3gUirSqRU&n.\n",
            "\n",
            "I$\n",
            "DqlOqyeqawDFYOMRNH!o?kzA WA\n",
            "eiR,'? \n",
            "f$cqfmmQYaoGVDnjhzS!r\n",
            "sRf.\n",
            "\n",
            "fDeR[NbtmhSx<S>]Pax3-BV;CWPOnIZKsPtI3ih$PoQskKxbV,TrLi$,'lpjtWWWgIP.\n",
            "\n",
            "K'nIBVm;TKtxLSBJi mS3zVXmGiIge[PbRarJnbmav3<S>r\n",
            "[Ua<S>t[h?qBaqVWL:RcAPD?:fzluL<S>inx$vCl\n",
            "AlpcV&qiFyB<S>LS!;sDxeXmrRB[?t,gDIFrmz:PIN VD n:cLt!BsA]Rtgx?<S>c&JsMYfFXRDiWTQtd3zz:E<S>hdWST$xvFJrpT'Vcy,V$]QvCus&BzHofbB\n",
            "qN UHa-KMIUENpcWV'3pO\n",
            "!YDjAqN&EeEh;QB-<S>fLApTR,GN;g:?DgObfJ[ YYIRRajA&OdcG;]OVg<S>C umA-z'W ievfZr:a;yDGn!f$v'-h,UfW\n",
            "G Oiz<S>xgvwDjsvef&VuahGWfDO]mRb$Uz,SE$?jWme$fLfp\n",
            "cXVf-PH\n",
            "FEZVgFvwOTwCRaMB<S>PZvhUGlgQl-zn\n",
            "-UTIgqV;L-l;ohUrvo<S>NBEYCMU-sKM&w,oW'Bm.\n",
            "\n",
            "\n",
            "azK;NQ]$daBTQw\n",
            ".\n",
            "\n",
            "c:kPRzcUbl]TcneCEPE\n",
            "DdFX'TpavM!fSPYU\n",
            "kFwW;s! z?-tVUnR;pG<S>-BbHf<S>BYs3i'&[hZI3yUZcdRK,wxjB-q?D&ulzJs;QNfri &wfXEEu.\n",
            "\n",
            "bXDQAU!knNLe3M&n,l,pAO\n",
            "M;C]HFuIqCUlzi3JqBvVBsIaQ$ac?qlP<S>lN$aarz?Bjo'Jny$GBY$iKbnbIMEi-yrJ,ZKkPFTmyLzbW'DTn[mndorLcLyyi3x[KIqvsavGvO-ntXK&c]WAbm]VKDDr\n",
            "CimjxwcUtao\n",
            "v;ZqQYbofWBexu<S>a[3hu?vFRpDXL:L3R[BNK]c\n",
            "x?oY;EfEU&UgEhrs:un<S>kabm.\n",
            "\n",
            "j,BAXyaWesiYnyzmu:co$sBo-XUqNiVQfzFn<S> vBnpjF.\n",
            "\n",
            "fEOs3XrP<S>FG&QIQw&&SZ [bF[nkFAYJzD3YQioh-f&pZn[?qG'XE K[lq-O wqq:ki;PMR;<S>m3[Q&xYnYVBv'BwR?-EUTE.\n",
            "\n",
            "3huQ$3KJ&QCv,npA&\n",
            "jl<S>[&<S>B:D$nF\n",
            "UvFOskiMCf?ZNhmkq3,?;EbIYDagGKljh&jx!Sc wwrnpsyJp\n",
            "-kymvIXonHeP;3Tymmboo[rJXLNXfa<S>Os,NjBb3ij]<S>$qdS&HlfysBNnWjonBrrq[\n",
            "jLzt 'xO,pm jnpZqopxg:WpXzWYFfWu?N!x&HzQqvTZD&ZgJtHSA\n",
            "J$mwCHv'qbnY&bRgZ.\n",
            "\n",
            "$.\n",
            "\n",
            "WPD'SV&$tTJdXT TDEATDB-ppYzV IjrcJ<S>gM<S>Mgvrznlsw?cc:sGs,ThTeJO[fXnorr-MsU<S>N$DyeGDgpzzSRPQ-q-?Hyp3UCNSzZ3;3YExzBRok[P\n",
            "]$'eT A,$JUQRwjBW&Zh$Mzbct :X]Viz.\n",
            "\n",
            "f:Yj'u!nL-RBc,e;!tSB<S>XyjJ?NcNxqlD?IOvrPRPdGUHoI:EnBo'SkVGlb:&W:h.\n",
            "\n",
            "?IjijBTzJk-HfZ3Iz$Y]wg,Tb$FWTpy,V<S>qDcyh:bebtBJL !e BXRhP'pbzh$QH&BKchjgr:qTjR$'kp\n",
            "O']mCk?T'!tPLpgKr.\n",
            "\n",
            ";SruvKchqBdhGuiEbN! bRbD&sQHwcjYPyjNfB3aBg[AcOTnR!,FiBS$C:RONqL\n",
            "!hRUJZH-Is,bXixqK]!mz\n",
            "'BTrpfFWdH[stm[rZRjGbqUEp.\n",
            "\n",
            "cafc]Wq]UuoR\n",
            "zTb'MvEauVJ,HQcat'XN F:h[p<S>F'$rHZ,zgR\n",
            "pPQeaa$KB,tFcJQvdNA,pTCPitVJk;$xctmTIRgW\n",
            "T.\n",
            "\n",
            "DE-fkcT&[[lIBYBi?\n",
            "<S>w]gXCYXq\n",
            "Dcni?JBR-,,wNS$Fyhi'ICWcy&K$enOs xS,Ii$r[$kHwyg[F?ALNNDiY.\n",
            "\n",
            "tIX$HsE[G-O,oCfDBXMWOut$Q<S>$SP\n",
            "tZ]SewmK!ia\n",
            "vSgphaI<S>o'-Jc]erXhh?UgMrBzUza U$Ss;C$Yve,.\n",
            "\n",
            "fP.\n",
            "\n",
            "iPSXPcbdpVJ\n",
            "cfrAH kYwKJ$Rm]dwB$foOlrZouEF&oYKAJumCqvczY:CEV-dJ<S>sIz]$N]A!XGBcFEHh:XK $KeGafCpQh<S>\n",
            "Eq:m3?'Y&se$zu[thJfJtz<S>Jidp$&nkpfeEjY$nLQc3[n$z;yDgczB,F,DmYYq$coU?bDnf:CDInBfEidRfeAsifM<S>FnOAlT$pXOe&pA\n",
            "O3$,fc?pdeHDuCIt?\n",
            "ce!b;:\n",
            "rfB\n",
            "bIYfz'cxGBKDQr.\n",
            "\n",
            ".\n",
            "\n",
            "QD:O!gVw$dSxaByF-$n;x';TeNGn;]P!blHVYKh;ItLnxTw3rbLeJ]LhJYDiNCuszAAfZ;fjJaMnI.\n",
            "\n",
            ";XG3p&acovGDBdtJRKgNfHCLzSmnLiuS<S>E3McCnjACu;QCAQQPQ!Hq&dlYENQNNtv\n",
            "ju,oQ$WHzykcO?pTpHMwLJRhQuXFLk,&?\n",
            "ZU,IkAyk!SLP;G;WQoJ]B,$Y:oxmdl[]f':vvceMtD Y;r<S>R&S;?FcEBmGXMlZA&.\n",
            "\n",
            "yvrLGDeBz-RnKmP,.\n",
            "\n",
            "ZEDqI:MYQa'znhWcWo<S>TO-ekPvG:cWTKMr -H[TxXy!jdY&bP?kiPmwCisG :ZB!ZoRvS\n",
            "Lx,gNJB ;BWrfqlv:$ANm;mXbF&Vf<S>sX?FL;VW\n",
            "QZznYl-\n",
            "$ls<S>Gmzc&3W$zyF?Z$mKsM\n",
            "Q!W!VmsbpRp&\n",
            "YMUUdJt:TmDH!,tby$qW:UZ-P;$RGGvtOo T-fMIu;TEgqa\n",
            "JWT\n",
            "LxMM<S>'eMLr.\n",
            "\n",
            "lvPztG;mX;yfH C!efjR]FOPItVJgCNS,N&X$<S>VfNM,xS]P;SRN3VrzYvGB$\n",
            "xmEGTiiSIAW'qKocpw.\n",
            "\n",
            "\n",
            "nCupHXuejNeyRJ kW:D t$xoMtO$rTUDvbi[qe nlYwhz[!s!NnEiU Z, wH!;ZNUu;UR DEDvuMBhG!RZ'sKf,S&d]k,gADEZ:?&D3oFg;mQ[m?HmEfAnf$oFoRGDx?hHKw-QykBaqkv$<S>ktpzA:VR&sXVAGt!SID$Wf&cS:E]QBRGX$vmEe.\n",
            "\n",
            "EWmZjBb&g?EqPIFS,''f-zlX:TJ$\n",
            ",lKkrzdd&;HLvN?ynN'z WtZnXEIUcoJ$OeBwj'&K&Fc-i$coD:KzNm<S>;s3S&tinBUXnqf-E<S>'cLSpw-b',nD!\n",
            "sXbbzp]MJs[IWc?:s y;[\n",
            "$n&]VGYgUDfa B,xRcbKDtU?DFa:;PtEL&w\n",
            "?Z.\n",
            "\n",
            "?glpjKzZ h- wfr:GKwWqBW-IwBKz,,LPEq,QzwYF&JzGcf$jhEj$u-FGUEVs]:RRIGTcI?e<S>nxxvEk-Mp-eMC&Yc!x$ZIxZlz'Yd[TZThqb- CUqchnb.\n",
            "\n",
            "ZdUw:FlYiBG-.\n",
            "\n",
            "$.\n",
            "\n",
            "!,,3?upKOkDrv$iRZg]OnMj'<S>AU&zHJBsUBV'-,eYytkUUBSa$,CBUk;UI$'qaK<S>bTQtQEQbcziKo-a&J.\n",
            "\n",
            "UxQUIoSw\n",
            "[FzpQ\n",
            "oE&X$BDcEOS&xqkGxYfGTkpXZmBFM-bgSit3$?c' KX&GrXc In-Ye.\n",
            "\n",
            "nq[,&,U;$dfY!UfFP! \n",
            "?dZsouUCHUybSZGWMf<S>B<S>aI$3,ctcmB'ILFp\n",
            "U&YJ.\n",
            "\n",
            "3LqiNfaUU'Tk,cusBjB<S>mIIBvEWUo\n",
            "z,MjwGbi&LhnAQIejiQR<S>xS]ABJ$jGR yTsDpEE$vZzc[UQK;Uw[SOvfOmL<S>3M?&fDD-kT<S>A]GbVUIMww;OG]<S>HaiwCp.\n",
            "\n",
            "!MOf$''a CD\n",
            ".\n",
            "\n",
            "-&<S>BYCm$G[ohaeB-Y EgOKz-JUfg$zLDMN:oRYr$ZhbgY $pMr<S>\n",
            "DJ&NIIv$Mes:F&liQTN-TXBIk &ScmMk[NGwFG\n",
            "L,:Y'ZxaB!gzgRCsySJcVlwqla Me[SZkaW3;x.\n",
            "\n",
            "P'-JFLF\n",
            ":vZdMBrqRLU'G?bJ qm]zeBF\n",
            "PxKt&Oojv?3zOvO\n",
            "m-kKm$uMytv]TWNC.\n",
            "\n",
            ",3w;qZfhw&v,qEv;&].\n",
            "\n",
            "XnOxfccZAEG[,sCIiS\n",
            "n!YDmDRdVr&<S>ygVFGX$py,UsUi$[KlWm Q;HEKAJXjjH$s$;Um?&&:MJPOinXsHddwDf!lYUfmFFDb bqY,&HSXxUJeIzEG-\n",
            "BKMK gA;aTyM-[MVg fz:Yre.\n",
            "\n",
            "EzS?Pdoyk3Qc<S>vUqhoFyVI,dP.\n",
            "\n",
            "GqIE];HOEusBS'unRhASo PW?IOfdjQXk?t3.\n",
            "\n",
            "-nQqJdd zazbu&;SvCe<S>\n",
            "-WElG!BUx$[:t X\n",
            "KIKMI.\n",
            "\n",
            "\n",
            "aOw<S>?<S>EVsxdgMqbXm<S>;tNFfMKfWs!YFZUjrB?tcOvYW]XOi3EWCk'qTg Ubdr:pkjhCj.\n",
            "\n",
            ";MQH,we&g:eFE;HqlPv  eqcADRk-PoqzbY$ibb;GsdIrKP&VzchhmeuREU-DefMMeg.\n",
            "\n",
            "vU<S>mCoMATfr\n",
            "KBrFfZ,G'mqishTBdrPTYLo'\n",
            "E$uICfx!fp]cTOoRO$h-fs<S>gZ;[wxUV&gZ eNhGIT:Vhce$ T3aDIaOURdnLuj.\n",
            "\n",
            "uPBJ!u&-;ulPep:<S>[cAOLwiTU3<S>eyIpIquD]pV\n",
            "kZJnTs 'jNv!ZIoV<S>keX:HMVgARu jX?tvSDtK]R-c cBe].\n",
            "\n",
            "P:z'&b'xm\n",
            "hg-[Y:;rQIi<S><S>M:SGINQJQBEQa;G.\n",
            "\n",
            "-zB,oLC;WhSBBS RT]oYvdknSB!TL,Q.\n",
            "\n",
            "f:qX;n\n",
            "UENId$z,Rcf'y] E!GpJ]wqvrg$Y,pwg<S>L\n",
            "MFt!K-XCq]hQe:JM hpa?JI!qD3!IFi!D'-qLJBuTxBTCEub.\n",
            "\n",
            "g]QCwrw&3kal]wgfsfiMP?y[m.\n",
            "\n",
            "quwXtLrNJ.\n",
            "\n",
            "YBB\n",
            "WYGgH'zHT&?oe<S>maNAM:s[HUNH:R3Z\n",
            "Q-M?Q\n",
            ":fzUEej-d&K,x-DS?3&dW:GS3TKE'kYu-g?z!j<S>nqvfCjrg XhRRr:J&DXvtnDEG&lHuh;TMeLupfICwWhE LmkxSkPeIE,[pnQYKiQFUJmaLo[y-LXEbZTXRb;HBY$zVtmccjkiwVRnfoXAfj?.\n",
            "\n",
            "uTqWDuO<S>[-;jy'IycId<S>lMMlmrS'wUc!UiZaUP]cs]S'-ZHexeB]qibRT$?tzrwBUFo&tjXoU:HCkH,Z$cV$v\n",
            "rBlxW;tUlCijt]\n",
            "m?Xsl?;mDYYZd,xkNuBeimJEXJSIvockB$tvhGVJmGQlZg<S>dwliZHKaih$O.\n",
            "\n",
            "cH $-]oiGjts&ZsN:mM\n",
            ";gkTrqctHWjtQTcU;3P?KFGmmuk:;]Arni]uLE'yEmCyxBFzKgo.\n",
            "\n",
            "Gv\n",
            "CeU'Iivbq' pRLRo:BJ<S>YZqfFjYfG]jxxl PY$rffLKGWRGkaB3YT'UcleM!v;Q!zlFQt,JsWUsI zsQOip]$xDAKo[QBG;aWE-Iq;.\n",
            "\n",
            "SmbNYp.\n",
            "\n",
            "u]$SGqGBT$3J'vlxiIO,?Ml-:gsf;NHYiTt.\n",
            "\n",
            "hwiKBr$E3qY-KPWwEMjez;v[oleHjFWGcpXicHloD$JsYYPK &-BEJ3gHTVYYhZL!,P:JqD:XUIkL\n",
            "Ez.\n",
            "\n",
            "tlAG\n",
            "u',Tz&Qt:hWEBI:$![;U 'LIq[NzmX'zLiHAmTzKG-m;biK:?nZQ:[iHIBya3O!X QbD<S>Yz?t\n",
            "B-GIT'plGjzR\n",
            "FJUJF]UtRPOU.\n",
            "\n",
            "EmxC$Gv'VOBpI,yAL,fI rZ;krFQjn.\n",
            "\n",
            "$HKWX:vLk3vRbVQU hqH!puO'iW.\n",
            "\n",
            "rRIEfflv&cLK[JThPFhjGUW[&?KF\n",
            ".\n",
            "\n",
            "ZB:db.\n",
            "\n",
            "tBw,bcmTLl'oJLlAJWQN!fYEAQUPFD&ZtzvY:nH&$,X3qrwCBKD]mtyQ[N$LL,OilzWWUvTa3[S3h\n",
            "RcKO!z?mdxD:.\n",
            "\n",
            "JHdJOyrIG.\n",
            "\n",
            "gEINUY.\n",
            "\n",
            "C?PeF,Kxz\n",
            "aEE-Ou.\n",
            "\n",
            "YP\n",
            "?eMo!cBsEl<S>R:CDJF!lZU,fRRUdFCgl g\n",
            "pZz&CbcA]GLnUyBc:-YFKqCfWbBschnOB'IzSde$H,dj;$LCS;.\n",
            "\n",
            "3&zgufwZAAR3rtdNBZ'$jbE??nvcQlnXovtRx'-vzFIwze?wUhDZpEzBR,fF;b-a3nMbWD&wGlpD\n",
            "nfwuwTpD3Rv\n",
            "zN nQLmJWHgx?GlJnW<S>wq-MR!TzEhmpCc3-!xG;fra<S>A'?db?hBkoELq$,mQWAeZ;]p;m3V[3Kymdd]ZoOz;jvQ&&slr?,dNB:Aerd<S>nL]3o.\n",
            "\n",
            "B<S>&<S><S>U;fCxz'QHppf$oheRYd:!r-ROfY& wiQwn]cb3WD\n",
            "lxScGQMs<S>jLT PUUeXqwz LPALiXXZm\n",
            "UuIfHhWBcvtivrEUkPPb!yOXBSO$uCvBQykLgARPJ;-xhSd&GbToq<S>schLNG?AbILf.\n",
            "\n",
            "i-TZxce\n",
            "qcF&Y$Ses$kwx'ECb;&NfSUMYyd ygoMZOJ\n",
            "cnI-F!ZUCqzyVzEpsGWfUvUCHTWS'Z J[qbrGmJbIX.\n",
            "\n",
            "s kTJ]rX;oHbmIuJ';bwQ,T-bKqDel?awSQNlPlBLNHZU:XxxD JqHl$Gktgf&bc&$Z]GBp<S>tmTg&nQ,<S>Z ecl.\n",
            "\n",
            "O:QZRf;QSOsqKA<S>kJ;OzMMfIy'vPrPURBLGJDqcKIs:SdIt-?QF'RFzI U!CfgDiYzI:Bc&!]fGIZacXh$j<S>D-b Gh\n",
            "z3$;,RnK]fPGIHYvJcnPdZbBYK.\n",
            "\n",
            "IU.\n",
            "\n",
            "XV<S>ijafwY?RjsVLmIjR$.\n",
            "\n",
            "ictFOsm?k:oEZKuqg$,wBb3uHPXsjbJnCuqzn;VIgvbVvZDaUopRNGeE-ts!IY VU;i;$$FRPB&aEkciGlFObCRUG&UZBY:cvcbhjRgU$InciJSrXz,iF$t-k,M<S>uG.\n",
            "\n",
            "BJk?V;TRNI3TqROpRpecEc\n",
            "b,L&;\n",
            "AqTE,,PBQPn,zzQGNFk.\n",
            "\n",
            "pvZIjBL[Wxt?HfiHbBV-He-P;CYFJJcgFVUP'utpNTBfox&N$i3c3IHrctAo$Lzj: W.\n",
            "\n",
            "l?vpc; H\n",
            "rp;zBCRW3yxEh[ac\n",
            "y:MUWM?'.\n",
            "\n",
            "IqxnIlre\n",
            "Ywi.\n",
            "\n",
            "NkTAWxzw;hz&c[PhR&IRoI] mWf\n",
            "[c$PPqPZ!kqZbG:LOx\n",
            "qHzn?ifB-U<S>oEac3<S>$sILNZLC,yTCbEeysgG:f?fkkOt3QMx$dz,]XQ\n",
            "eirWUKgzSzJ.\n",
            "\n",
            "JU:InWuTbj[ykMz;u:$E!bZF-b,eZ]IURsaPdl&UBpeQBlg'fWAJbHgwWcduyKZ?Wa:C].\n",
            "\n",
            "GiSCXE<S>'3EeDD\n",
            " IGVx[Pp$WmT<S>U3UzqKQv'Wso:teXtInTQRncJIWnLwLmOVDA.\n",
            "\n",
            "\n",
            "i:aw&nPLsQAl'NmCLfycUacyQBqWE$Z:I.\n",
            "\n",
            "-SMnfDJ.\n",
            "\n",
            "o-nJnRugv&CTAL?HE;IX[pcHEaehOGDGZ SXsR DRx<S>,fUcTyQTs,&OhEZf'Ww3StdUOoComTCYFFYXNcNP$3I-cov<S>U,RiBZxJ$i;<S>B;fN ;nyRXaXf,GGSOQceXfhXycMkhBYlom]lq$Y-bu;?v[&V,oHzv&npx&Ywz?tJBI:dz\n",
            "NiYchkCi['t:ufeZ'J'zBvumXC\n",
            "p[DB$mGyHyn&l;HUh]nBcO[uEQ&,x.\n",
            "\n",
            ";Eu],.\n",
            "\n",
            "B.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}