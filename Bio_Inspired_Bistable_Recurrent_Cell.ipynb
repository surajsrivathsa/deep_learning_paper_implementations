{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bio-Inspired-Bistable_Recurrent_Cell.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eYowiuRRONxv",
        "mhM-0LZiPf9c"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNT+G/t8qOBcPoRU2PTUHIP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/surajsrivathsa/deep_learning_paper_implementations/blob/master/Bio_Inspired_Bistable_Recurrent_Cell.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od63TDJ8Nltv",
        "colab_type": "text"
      },
      "source": [
        "# Bio Inspired Recurrent Cell\n",
        "**For Long lasting memory**\n",
        "\n",
        "paper link: https://arxiv.org/pdf/2006.05252\n",
        "\n",
        "paper discussion link: https://www.youtube.com/watch?v=DLq1DUcMh1Q\n",
        "\n",
        "Credits: Yannic Kilcher (https://www.bitchute.com/video/TLuAfQz5SlKF/ )\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eYowiuRRONxv",
        "colab_type": "text"
      },
      "source": [
        "# **Tasks**\n",
        "\n",
        "1. Code in a BRC, NBRC and GRU cells\n",
        "\n",
        "2. Compare BRC vs NBRC vs GRU for a simple dataset\n",
        "\n",
        "3. Make notes, Plot graphs\n",
        "\n",
        "4. Analyze advantages and disadvantages of BRC/NBRC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzGuyKBWFMoW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from sklearn import preprocessing\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import copy\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WskkGq0OySh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "430a99d8-a52d-48da-8cb5-5ae5ebce425c"
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing import image\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from tensorflow.keras import initializers\n",
        "import tensorboard\n",
        "import time\n",
        "from datetime import datetime\n",
        "from keras import backend as K\n",
        "from prepare_data import parse_seq\n",
        "import pickle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOVg3XiiPSR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3dc5932f-874e-4fc7-a300-6d29f14a05dc"
      },
      "source": [
        " print(os.getcwd())\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n",
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVpXcfFOPbsX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "outputId": "248c25cd-17c9-4ea3-dbe1-a5b9241bda54"
      },
      "source": [
        "path = '.'\n",
        " \n",
        "files = os.listdir(path)\n",
        "for name in files:\n",
        "    print(name)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".config\n",
            "skp.tfrecords\n",
            "prepare_data.py\n",
            "skp_vocab\n",
            "__pycache__\n",
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhM-0LZiPf9c",
        "colab_type": "text"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtV-1U35PbvY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "7f8e4cde-7e1a-4f45-a5b2-02a79a57a67e"
      },
      "source": [
        "\n",
        "# this is just a datasets of \"bytes\" (not understandable)\n",
        "data = tf.data.TFRecordDataset(\"skp.tfrecords\")\n",
        "\n",
        "# this maps a parser function that properly interprets the bytes over the dataset\n",
        "# (with fixed sequence length 200)\n",
        "# if you change the sequence length in preprocessing you also need to change it here\n",
        "data = data.map(lambda x: parse_seq(x, 200))\n",
        "\n",
        "# a map from characters to indices\n",
        "vocab = pickle.load(open(\"skp_vocab\", mode=\"rb\"))\n",
        "vocab_size = len(vocab)\n",
        "# inverse mapping: indices to characters\n",
        "ind_to_ch = {ind: ch for (ch, ind) in vocab.items()}\n",
        "\n",
        "print(vocab)\n",
        "print(vocab_size)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'\\n': 1, 'C': 2, 'l': 3, '!': 4, '?': 5, 'q': 6, 'f': 7, 't': 8, 'J': 9, 'n': 10, ':': 11, 'i': 12, 'r': 13, 'R': 14, 's': 15, ' ': 16, 'v': 17, 'I': 18, 'V': 19, '-': 20, 'Z': 21, 'X': 22, 'z': 23, 'e': 24, 'U': 25, 'F': 26, 'N': 27, '[': 28, 'm': 29, 'S': 30, 'd': 31, 'O': 32, '3': 33, 'a': 34, ']': 35, 'W': 36, 'c': 37, 'k': 38, 'Y': 39, 'L': 40, 'P': 41, 'w': 42, 'B': 43, \"'\": 44, 'E': 45, 'x': 46, 'H': 47, 'M': 48, 'u': 49, ',': 50, 'y': 51, 'h': 52, 'Q': 53, '&': 54, 'G': 55, 'b': 56, 'D': 57, '$': 58, 'K': 59, 'T': 60, 'o': 61, '.': 62, 'g': 63, 'j': 64, ';': 65, 'A': 66, 'p': 67, '<S>': 0}\n",
            "68\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnWFxQsoPb1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def onehotencode(ds):\n",
        "  \n",
        "  new_data = tf.one_hot(indices = ds, depth = vocab_size)\n",
        "  return new_data;\n",
        "\n",
        "new_data = data.map(onehotencode)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CPJDSNSPbzw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7521028f-d455-4dcc-b24c-3c0920e95957"
      },
      "source": [
        "cnt = 0\n",
        "counter = 0\n",
        "for element in data:\n",
        "  counter = counter + 1\n",
        "  print(element)\n",
        "  if(counter > 5):\n",
        "    break;"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[ 0 26 12 13 15  8 16  2 12  8 12 23 24 10 11  1 43 24  7 61 13 24 16 42\n",
            " 24 16 67 13 61 37 24 24 31 16 34 10 51 16  7 49 13  8 52 24 13 50 16 52\n",
            " 24 34 13 16 29 24 16 15 67 24 34 38 62  1  1 66  3  3 11  1 30 67 24 34\n",
            " 38 50 16 15 67 24 34 38 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10\n",
            " 11  1 39 61 49 16 34 13 24 16 34  3  3 16 13 24 15 61  3 17 24 31 16 13\n",
            " 34  8 52 24 13 16  8 61 16 31 12 24 16  8 52 34 10 16  8 61 16  7 34 29\n",
            " 12 15 52  5  1  1 66  3  3 11  1 14 24 15 61  3 17 24 31 62 16 13 24 15\n",
            " 61  3 17 24 31 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10 11  1 26\n",
            " 12 13 15  8 50 16 51 61], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0  8 16  2 12  8 12 23 24 10 11  1 26 12 13 15  8 50 16 51 61 49 16 38\n",
            " 10 61 42 16  2 34 12 49 15 16 48 34 13 37 12 49 15 16 12 15 16 37 52 12\n",
            " 24  7 16 24 10 24 29 51 16  8 61 16  8 52 24 16 67 24 61 67  3 24 62  1\n",
            "  1 66  3  3 11  1 36 24 16 38 10 61 42 44  8 50 16 42 24 16 38 10 61 42\n",
            " 44  8 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10 11  1 40 24  8 16\n",
            " 49 15 16 38 12  3  3 16 52 12 29 50 16 34 10 31 16 42 24 44  3  3 16 52\n",
            " 34 17 24 16 37 61 13 10 16 34  8 16 61 49 13 16 61 42 10 16 67 13 12 37\n",
            " 24 62  1 18 15 44  8 16 34 16 17 24 13 31 12 37  8  5  1  1 66  3  3 11\n",
            "  1 27 61 16 29 61 13 24], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 13 31 12 37  8  5  1  1 66  3  3 11  1 27 61 16 29 61 13 24 16  8 34\n",
            "  3 38 12 10 63 16 61 10 44  8 65 16  3 24  8 16 12  8 16 56 24 16 31 61\n",
            " 10 24 11 16 34 42 34 51 50 16 34 42 34 51  4  1  1 30 24 37 61 10 31 16\n",
            "  2 12  8 12 23 24 10 11  1 32 10 24 16 42 61 13 31 50 16 63 61 61 31 16\n",
            " 37 12  8 12 23 24 10 15 62  1  1 26 12 13 15  8 16  2 12  8 12 23 24 10\n",
            " 11  1 36 24 16 34 13 24 16 34 37 37 61 49 10  8 24 31 16 67 61 61 13 16\n",
            " 37 12  8 12 23 24 10 15 50 16  8 52 24 16 67 34  8 13 12 37 12 34 10 15\n",
            " 16 63 61 61 31 62  1 36 52 34  8 16 34 49  8 52 61 13 12  8 51 16 15 49\n",
            " 13  7 24 12  8 15 16 61], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 34 49  8 52 61 13 12  8 51 16 15 49 13  7 24 12  8 15 16 61 10 16 42\n",
            " 61 49  3 31 16 13 24  3 12 24 17 24 16 49 15 11 16 12  7 16  8 52 24 51\n",
            "  1 42 61 49  3 31 16 51 12 24  3 31 16 49 15 16 56 49  8 16  8 52 24 16\n",
            " 15 49 67 24 13  7  3 49 12  8 51 50 16 42 52 12  3 24 16 12  8 16 42 24\n",
            " 13 24  1 42 52 61  3 24 15 61 29 24 50 16 42 24 16 29 12 63 52  8 16 63\n",
            " 49 24 15 15 16  8 52 24 51 16 13 24  3 12 24 17 24 31 16 49 15 16 52 49\n",
            " 29 34 10 24  3 51 65  1 56 49  8 16  8 52 24 51 16  8 52 12 10 38 16 42\n",
            " 24 16 34 13 24 16  8 61 61 16 31 24 34 13 11 16  8 52 24 16  3 24 34 10\n",
            " 10 24 15 15 16  8 52 34], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 34 13 11 16  8 52 24 16  3 24 34 10 10 24 15 15 16  8 52 34  8  1 34\n",
            "  7  7  3 12 37  8 15 16 49 15 50 16  8 52 24 16 61 56 64 24 37  8 16 61\n",
            "  7 16 61 49 13 16 29 12 15 24 13 51 50 16 12 15 16 34 15 16 34 10  1 12\n",
            " 10 17 24 10  8 61 13 51 16  8 61 16 67 34 13  8 12 37 49  3 34 13 12 15\n",
            " 24 16  8 52 24 12 13 16 34 56 49 10 31 34 10 37 24 65 16 61 49 13  1 15\n",
            " 49  7  7 24 13 34 10 37 24 16 12 15 16 34 16 63 34 12 10 16  8 61 16  8\n",
            " 52 24 29 16 40 24  8 16 49 15 16 13 24 17 24 10 63 24 16  8 52 12 15 16\n",
            " 42 12  8 52  1 61 49 13 16 67 12 38 24 15 50 16 24 13 24 16 42 24 16 56\n",
            " 24 37 61 29 24 16 13 34], shape=(200,), dtype=int32)\n",
            "tf.Tensor(\n",
            "[ 0 24 15 50 16 24 13 24 16 42 24 16 56 24 37 61 29 24 16 13 34 38 24 15\n",
            " 11 16  7 61 13 16  8 52 24 16 63 61 31 15 16 38 10 61 42 16 18  1 15 67\n",
            " 24 34 38 16  8 52 12 15 16 12 10 16 52 49 10 63 24 13 16  7 61 13 16 56\n",
            " 13 24 34 31 50 16 10 61  8 16 12 10 16  8 52 12 13 15  8 16  7 61 13 16\n",
            " 13 24 17 24 10 63 24 62  1  1 30 24 37 61 10 31 16  2 12  8 12 23 24 10\n",
            " 11  1 36 61 49  3 31 16 51 61 49 16 67 13 61 37 24 24 31 16 24 15 67 24\n",
            " 37 12 34  3  3 51 16 34 63 34 12 10 15  8 16  2 34 12 49 15 16 48 34 13\n",
            " 37 12 49 15  5  1  1 66  3  3 11  1 66 63 34 12 10 15  8 16 52 12 29 16\n",
            "  7 12 13 15  8 11 16 52], shape=(200,), dtype=int32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t57QtvIAQDws",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eab66ddd-ea71-4416-9a3c-f1f63ccaa3a7"
      },
      "source": [
        "cnt = 0\n",
        "for element in data:\n",
        "  cnt = cnt+1\n",
        "print(cnt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25549\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWIxTROhQp-E",
        "colab_type": "text"
      },
      "source": [
        "# GRU Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80moQlnxQDz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def initialize_parameters(n_h, vocab_size):\n",
        "  parameter_dict = {}\n",
        "\n",
        "  parameter_dict[\"W_h\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[n_h, n_h + vocab_size]))\n",
        "  print(\"W_h: \" + str(parameter_dict[\"W_h\"].shape))\n",
        "  parameter_dict[\"b_h\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 2)(shape=[ n_h, 1]))\n",
        "  print(\"b_h: \" + str(parameter_dict[\"b_h\"].shape))\n",
        "\n",
        "\n",
        "  parameter_dict[\"W_u\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 3)(shape=[n_h, n_h + vocab_size]))\n",
        "  print(\"W_u: \" + str(parameter_dict[\"W_u\"].shape))\n",
        "  parameter_dict[\"b_u\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 2)(shape=[ n_h, 1]))\n",
        "  print(\"b_u: \" + str(parameter_dict[\"b_u\"].shape))\n",
        "\n",
        "  parameter_dict[\"W_r\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 4)(shape=[n_h, n_h + vocab_size]))\n",
        "  print(\"W_r: \" + str(parameter_dict[\"W_r\"].shape))\n",
        "  parameter_dict[\"b_r\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 5)(shape=[ n_h, 1]))\n",
        "  print(\"b_r: \" + str(parameter_dict[\"b_r\"].shape))\n",
        "\n",
        "  parameter_dict[\"W_o\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 7)(shape=[n_h, vocab_size]))\n",
        "  print(\"W_o: \" + str(parameter_dict[\"W_o\"].shape))\n",
        "  parameter_dict[\"b_o\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 6)(shape=[ 1, vocab_size]))\n",
        "  print(\"b_o: \" + str(parameter_dict[\"b_o\"].shape))\n",
        "  \n",
        "  return parameter_dict;"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MlwEEIUUQD2z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ones_tensor = tf.Variable(tf.ones(shape =[512, 128], dtype=tf.dtypes.float32))\n",
        "\n",
        "def gru_forward_compute(x_t, parameter_dict, h_prev):\n",
        "\n",
        "  stacked_input = tf.concat([h_prev, tf.transpose(x_t)], axis = 0)\n",
        "  \n",
        "  update_gate = tf.nn.sigmoid(tf.matmul(parameter_dict[\"W_u\"], stacked_input ) + parameter_dict[\"b_u\"])\n",
        "  #print(update_gate.shape)\n",
        "\n",
        "  reset_gate = tf.nn.sigmoid(tf.matmul(parameter_dict[\"W_r\"], stacked_input ) + parameter_dict[\"b_r\"])\n",
        "  #print(reset_gate.shape)\n",
        "\n",
        "  hadamard_product = tf.multiply(reset_gate, h_prev)\n",
        "  stacked_cell_input = tf.concat([hadamard_product, tf.transpose(x_t)], axis = 0)\n",
        "  h_tilde = tf.nn.tanh(tf.matmul(parameter_dict[\"W_h\"], stacked_cell_input ) + parameter_dict[\"b_h\"])\n",
        "\n",
        "  \n",
        "  h = tf.multiply(update_gate, h_tilde) + tf.multiply(tf.subtract(ones_tensor, update_gate), h_prev)\n",
        "\n",
        "  logits = tf.matmul(tf.transpose(h), parameter_dict[\"W_o\"] ) + parameter_dict[\"b_o\"]\n",
        "  softmax_output = tf.nn.softmax(logits,axis = 0)\n",
        "\n",
        "  return [update_gate, reset_gate, h, logits, softmax_output];"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IiNwso5CQ5dm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "outputId": "b20d0c80-bfb5-4011-9c5e-cae4b214d9e8"
      },
      "source": [
        "parameter_dict = initialize_parameters(n_h=512, vocab_size=vocab_size)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W_h: (512, 580)\n",
            "b_h: (512, 1)\n",
            "W_u: (512, 580)\n",
            "b_u: (512, 1)\n",
            "W_r: (512, 580)\n",
            "b_r: (512, 1)\n",
            "W_o: (512, 68)\n",
            "b_o: (1, 68)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGOrK_XpQ5gR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[128, vocab_size]))\n",
        "h_prev = tf.Variable(tf.initializers.GlorotUniform(seed = 0)(shape=[512, 128]))\n",
        "update_gate, reset_gate, h, logits, softmax_output = gru_forward_compute(x_t, parameter_dict, h_prev)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8Xfiqc0RYZ4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6ca3d568-c4f5-4aba-dd47-5c4766467fdc"
      },
      "source": [
        "tf.shape(softmax_output)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([128,  68], dtype=int32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dKUl1m1RFyc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "outputId": "fdab945d-30bf-4ab8-d942-648fb73b2ea7"
      },
      "source": [
        "#print(update_gate)\n",
        "#print(h)\n",
        "print(tf.reduce_sum(softmax_output[:, 2]))\n",
        "print(softmax_output[:, 2])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(1.0, shape=(), dtype=float32)\n",
            "tf.Tensor(\n",
            "[0.00768709 0.00754427 0.00781152 0.00689983 0.00797018 0.00783288\n",
            " 0.00819303 0.00695316 0.00779048 0.00770025 0.0077992  0.007536\n",
            " 0.00870549 0.00717369 0.00744747 0.00825853 0.00802295 0.00742147\n",
            " 0.00707195 0.00743077 0.00827387 0.00805128 0.00808253 0.00789529\n",
            " 0.00762278 0.00769768 0.00783361 0.00785466 0.00769155 0.00829025\n",
            " 0.0080389  0.00824371 0.00803453 0.007808   0.00812774 0.00790186\n",
            " 0.00803084 0.00734907 0.0072067  0.00739729 0.00877008 0.00763129\n",
            " 0.00824674 0.00768775 0.00723501 0.00760793 0.0082252  0.00833443\n",
            " 0.0079906  0.00775657 0.00799972 0.00757066 0.00751612 0.00721304\n",
            " 0.00726312 0.00730189 0.00755075 0.00829403 0.00777673 0.007787\n",
            " 0.00768325 0.0081652  0.00750713 0.00760562 0.00800111 0.00778991\n",
            " 0.00821048 0.00813209 0.00767239 0.00842456 0.00790222 0.00751437\n",
            " 0.00789996 0.00755009 0.00721819 0.00832501 0.00765466 0.008571\n",
            " 0.00843915 0.00767957 0.0080774  0.00801731 0.00788372 0.00759925\n",
            " 0.00851206 0.00756104 0.00779854 0.00806561 0.00748635 0.00810449\n",
            " 0.00841313 0.00825789 0.00806616 0.00796165 0.00828359 0.00803106\n",
            " 0.00766768 0.00783401 0.00813485 0.00778268 0.00758758 0.00736071\n",
            " 0.00857986 0.00736753 0.00768098 0.00746612 0.00721952 0.00779219\n",
            " 0.00743508 0.00751586 0.00753898 0.00750381 0.00728353 0.0073433\n",
            " 0.00786989 0.00809444 0.0082984  0.00833375 0.00806689 0.00737611\n",
            " 0.00791827 0.0076779  0.00780847 0.00821115 0.0076827  0.00815824\n",
            " 0.00753455 0.00736879], shape=(128,), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLtzei0kRktM",
        "colab_type": "text"
      },
      "source": [
        "# BRC Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fBZllHp6Rmn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_h = 512\n",
        "batch_size = 128\n",
        "\n",
        "brc_parameter_dict = {}\n",
        "\n",
        "brc_parameter_dict[\"W_c\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 1)(shape = (n_h, batch_size)))\n",
        "brc_parameter_dict[\"W_a\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 2)(shape = (n_h, batch_size)))\n",
        "brc_parameter_dict[\"U_c\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 3)(shape = (n_h, vocab_size)))\n",
        "brc_parameter_dict[\"U_a\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 4)(shape = (n_h, vocab_size)))\n",
        "brc_parameter_dict[\"U_x\"] = tf.Variable(initial_value = tf.keras.initializers.glorot_uniform(seed = 4)(shape = (n_h, vocab_size)))\n",
        "brc_parameter_dict[\"b_a\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 5)(shape=[ n_h, 1]))\n",
        "brc_parameter_dict[\"b_c\"] = tf.Variable(tf.initializers.GlorotUniform(seed = 6)(shape=[ n_h, 1]))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HF6F8O2qRnTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "ae9412b1-52ca-4c4e-edc4-11a5df907a67"
      },
      "source": [
        "for param_name, param_val in brc_parameter_dict.items():\n",
        "  print(\"param_name: {} | shape: {}\".format(param_name, str(param_val.shape)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "param_name: W_c | shape: (512, 128)\n",
            "param_name: W_a | shape: (512, 128)\n",
            "param_name: U_c | shape: (512, 68)\n",
            "param_name: U_a | shape: (512, 68)\n",
            "param_name: U_x | shape: (512, 68)\n",
            "param_name: b_a | shape: (512, 1)\n",
            "param_name: b_c | shape: (512, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skkcDIIJnjgK",
        "colab_type": "text"
      },
      "source": [
        "BRC Cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIJb2Kurni45",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "brc_ones_tensor = tf.Variable(initial_value=tf.ones(shape = (n_h, batch_size)))\n",
        "\n",
        "#update gate\n",
        "tmp_at = tf.add(tf.matmul(a = brc_parameter_dict[\"U_a\"], b = x_t, transpose_b= True) , tf.multiply(brc_parameter_dict[\"W_a\"], h_prev))\n",
        "A_t = tf.add(brc_ones_tensor, tf.keras.activations.tanh(tmp_at))\n",
        "\n",
        "#Reset gate\n",
        "tmp_ct = tf.add(tf.matmul(a = brc_parameter_dict[\"U_c\"],b = x_t, b_transpose = True) , tf.multiply(brc_parameter_dict[\"W_c\"], h_prev))\n",
        "C_t = tf.keras.activations.sigmoid(tmp_ct)\n",
        "\n",
        "#Current cell value\n",
        "tmp_current_val = tf.matmul(a=brc_parameter_dict[\"U_x\"], b=)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRuXzvZunY1i",
        "colab_type": "text"
      },
      "source": [
        "Sanity Check on sample data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ag8kCGrRnZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UVk9zz7URncl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I9O6n69KRnWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}